{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "form-meaning-mapping.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei2RFUkqx09H"
      },
      "source": [
        "# Form2Meaning Mapping\n",
        "\n",
        "* Author: Stefano Scola\n",
        "* Supervisor: Giovanni Cassani\n",
        "* University: Tilburg University\n",
        "\n",
        "The purpose of this notebook is to give users a clear and easy to use approach to generate alligned word embeddings (Word2Vec) using the Compass Aligned Distributional Embeddings (CADE) libary. Moreover, it allows user to generate form-based semantic vectors from the names of fictional characters, by deploying two form-meaning mapping functions: Orthographic Semantic Consistency (OSC) & Linear Discriminative Learning (LDL).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vupEMXWkWVrG"
      },
      "source": [
        "# Word2Vec HyperParameters and Imports libraries\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wm4JCkNWYqR"
      },
      "source": [
        "min_count = 5\n",
        "size = 50\n",
        "model_type = 1\n",
        "window = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ9wW0AjZWjV",
        "outputId": "9967e8d5-41fe-4744-a029-90cc41497eec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzRzfSZe4vSc"
      },
      "source": [
        "PATH = \"drive/MyDrive/word_embeddings/ch_ya/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiVi-_0rPy-s"
      },
      "source": [
        "!pip install cade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ncn0ORmCx09P"
      },
      "source": [
        "# Imports\n",
        "\n",
        "# Plaintext2Emb\n",
        "import nltk\n",
        "import string\n",
        "import gensim\n",
        "import spacy\n",
        "import pickle as p\n",
        "import numpy as np\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "# Visualising the wordspace\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib import pyplot\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Loading the model\n",
        "from scipy import stats, spatial\n",
        "from sklearn import preprocessing\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# CADE\n",
        "import os\n",
        "import pickle\n",
        "#from cade.cade import CADE\n",
        "from sklearn.manifold import TSNE\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "\n",
        "# Visualisation\n",
        "import plotly.express as px\n",
        "\n",
        "\n",
        "# Classifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n1DDo_px09R"
      },
      "source": [
        "# Importing data\n",
        "Our approach takes two types of files. First, we need a labeled character list extracted from corpuses we wish to investigate. To do so create a .csv/.xlsx file, or multiple, in the labeled_names folder with this given structure:\n",
        "\n",
        "* title: the name of the file which contains the corpus where the name appears\n",
        "* full_name: the name of the character\n",
        "* newID: how the name is referenced in the corpus\n",
        "* gender: male/female\n",
        "* age_recoded: young/old\n",
        "* freq_sum: the cumulative frequency\n",
        "* type: Real/Talking/Madeup\n",
        "\n",
        "The second file we need are the corpus where each name appears, this shoule be placed in the corpus folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU0ZuGWVx09R"
      },
      "source": [
        "## Names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyGWPwW89X-T"
      },
      "source": [
        "# loading names selection\n",
        "complete_df = pd.read_csv(PATH + \"labeled_names/total_ChYA_names.csv\")\n",
        "# dropping useless? columns\n",
        "complete_df.drop(columns=[\"id\", \"age.stage.original\", \"name_age\"], inplace=True)\n",
        "\n",
        "complete_df.loc[ 28, \"full_name\"] = \"Sprout\"\n",
        "complete_df.loc[ 23, \"full_name\"] = \"Silky\"\n",
        "complete_df.loc[ 24, \"full_name\"] = \"Myrtle\"\n",
        "complete_df.loc[ 24, \"full_name\"] = \"Virginia\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3jUO-Appxdz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "957a03db-721f-4853-cfdd-058ce6808f46"
      },
      "source": [
        "complete_df.head(80)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>full_name</th>\n",
              "      <th>gender</th>\n",
              "      <th>rs_frequency</th>\n",
              "      <th>author</th>\n",
              "      <th>newID</th>\n",
              "      <th>age_recoded</th>\n",
              "      <th>freq_sum</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WILSON_dustbinbaby_2001</td>\n",
              "      <td>April Johnson</td>\n",
              "      <td>female</td>\n",
              "      <td>1525</td>\n",
              "      <td>WILSON</td>\n",
              "      <td>April_Johnson_WILSON_char</td>\n",
              "      <td>young</td>\n",
              "      <td>3122</td>\n",
              "      <td>Talking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ALMOND_jackdawsummer_2008</td>\n",
              "      <td>Ball</td>\n",
              "      <td>male</td>\n",
              "      <td>95</td>\n",
              "      <td>ALMOND</td>\n",
              "      <td>Ball_ALMOND_char</td>\n",
              "      <td>old</td>\n",
              "      <td>95</td>\n",
              "      <td>Talking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GAVIN_blackberryblue_2013</td>\n",
              "      <td>Blackberry Blue</td>\n",
              "      <td>female</td>\n",
              "      <td>17</td>\n",
              "      <td>GAVIN</td>\n",
              "      <td>Blackberry_Blue_GAVIN_char</td>\n",
              "      <td>young</td>\n",
              "      <td>249</td>\n",
              "      <td>Talking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FINE_charmschool_1999</td>\n",
              "      <td>Bonny Bramble</td>\n",
              "      <td>female</td>\n",
              "      <td>1387</td>\n",
              "      <td>FINE</td>\n",
              "      <td>Bonny_Bramble_FINE_char</td>\n",
              "      <td>young</td>\n",
              "      <td>1393</td>\n",
              "      <td>Talking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MURPHY_firstprizefortheworstwitch_2018</td>\n",
              "      <td>Brilliantine</td>\n",
              "      <td>female</td>\n",
              "      <td>143</td>\n",
              "      <td>MURPHY</td>\n",
              "      <td>Brilliantine_MURPHY_char</td>\n",
              "      <td>old</td>\n",
              "      <td>279</td>\n",
              "      <td>Talking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>FINE_uponcloudnine_2002</td>\n",
              "      <td>Stuart Terence Oliver</td>\n",
              "      <td>male</td>\n",
              "      <td>20</td>\n",
              "      <td>FINE</td>\n",
              "      <td>Stuart_Terence_Oliver_FINE_char</td>\n",
              "      <td>young</td>\n",
              "      <td>1782</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>FINE_troubleintoadpool_2012</td>\n",
              "      <td>Susan Harlow</td>\n",
              "      <td>female</td>\n",
              "      <td>533</td>\n",
              "      <td>FINE</td>\n",
              "      <td>Susan_Harlow_FINE_char</td>\n",
              "      <td>old</td>\n",
              "      <td>533</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>ROWLING_harrypotterandthedeathlyhallows_2007</td>\n",
              "      <td>Sybill Trelawney</td>\n",
              "      <td>female</td>\n",
              "      <td>6</td>\n",
              "      <td>ROWLING</td>\n",
              "      <td>Sybill_Trelawney_ROWLING_char</td>\n",
              "      <td>old</td>\n",
              "      <td>922</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>FINE_eatingthingsonsticks_2009</td>\n",
              "      <td>Tristram</td>\n",
              "      <td>male</td>\n",
              "      <td>1392</td>\n",
              "      <td>FINE</td>\n",
              "      <td>Tristram_FINE_char</td>\n",
              "      <td>old</td>\n",
              "      <td>2266</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>FINE_thestonemenagerie_1980</td>\n",
              "      <td>William Riley</td>\n",
              "      <td>male</td>\n",
              "      <td>747</td>\n",
              "      <td>FINE</td>\n",
              "      <td>William_Riley_FINE_char</td>\n",
              "      <td>old</td>\n",
              "      <td>747</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           title  ...    class\n",
              "0                        WILSON_dustbinbaby_2001  ...  Talking\n",
              "1                      ALMOND_jackdawsummer_2008  ...  Talking\n",
              "2                      GAVIN_blackberryblue_2013  ...  Talking\n",
              "3                          FINE_charmschool_1999  ...  Talking\n",
              "4         MURPHY_firstprizefortheworstwitch_2018  ...  Talking\n",
              "..                                           ...  ...      ...\n",
              "75                       FINE_uponcloudnine_2002  ...     Real\n",
              "76                   FINE_troubleintoadpool_2012  ...     Real\n",
              "77  ROWLING_harrypotterandthedeathlyhallows_2007  ...     Real\n",
              "78                FINE_eatingthingsonsticks_2009  ...     Real\n",
              "79                   FINE_thestonemenagerie_1980  ...     Real\n",
              "\n",
              "[80 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ7EXPSPx09T"
      },
      "source": [
        "## Corpus\n",
        "\n",
        "The corpus consist of 94 different books. \n",
        "\n",
        "Let's check if the names we wish to investigate appear in those books."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk3qFgB0x09T"
      },
      "source": [
        "\n",
        "#checking how many times we do not find the id in the story\n",
        "issues = 0\n",
        "for i in range(len(complete_df)):\n",
        "\n",
        "\n",
        "    # Test open\n",
        "    corpus = complete_df.loc[i].title\n",
        "    file_path = PATH + 'final_recoded_corpus/' + corpus + '_recoded.txt'\n",
        "    txt = open(file_path, \"r\").read()\n",
        "\n",
        "\n",
        "\n",
        "    # Testing name\n",
        "    name_tag = ''\n",
        "    name = complete_df['full_name'].loc[i]\n",
        "    #print('\\nName to look up:', name)\n",
        "    #print('\\nFile path: ', file_path)\n",
        "    #print('Preview: ', txt[:500])\n",
        "    id = complete_df[\"newID\"].loc[i]\n",
        "    #print(\"\\nID to check:\", id)\n",
        "\n",
        "    \n",
        "    # Name search\n",
        "    count_check = 0\n",
        "\n",
        "    for word in txt.split():\n",
        "\n",
        "        #tag = word.split('_')\n",
        "        #if word.endswith(\"_char\"):\n",
        "        if word == id:\n",
        "          count_check += 1\n",
        "          if name_tag == '':\n",
        "            name_tag = word\n",
        "\n",
        "    if count_check == 0:\n",
        "      issues += 1\n",
        "      print('\\nName to look up:', name)\n",
        "      print('\\nStory file: ', corpus)\n",
        "      print('Preview: ', txt[:500])\n",
        "      print(\"\\nID to check:\", id)\n",
        "\n",
        "      print('Tag: ', name_tag)\n",
        "      print('\\nExpected name count: ', complete_df['rs_frequency'].loc[i])\n",
        "      print('Resulting name count: ', count_check)\n",
        "      print('\\nCumulative freq count: ', complete_df['freq_sum'].loc[i])\n",
        "      print(\"index in the dataframe:\", i)\n",
        "\n",
        "print(\"\\nNumber of issues\", issues)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDqOZRvOx09U"
      },
      "source": [
        "# Cleaning corpus\n",
        "\n",
        "The corpus is cleaned and saved in the folder \"cleaned_corpus\". \n",
        "\n",
        "We have lowercased, tokenized and removed stopwords."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ly8rgmOAsLL"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwoEiaXtx09U"
      },
      "source": [
        "# Function to clean and prepare the corpus for word2vec\n",
        "\n",
        "def clean_text(test_text, preview=False):\n",
        "    # Separating the sentences of the corpus\n",
        "    nltk_tokens = nltk.sent_tokenize(test_text)\n",
        "\n",
        "    # Split each sentence into word lists\n",
        "    tokenizer = RegexpTokenizer(r'[a-zA-Z0-9_\\.]+\\b')\n",
        "    split_sent = [tokenizer.tokenize(sent.lower()) for sent in nltk_tokens] # mod... sent.lower() to avoid doubles\n",
        "\n",
        "    # Lemmatization with Spacy\n",
        "    nlp = spacy.load('en')\n",
        "    \n",
        "    #temp = []\n",
        "    lemma_sent = []\n",
        "\n",
        "    for sent in split_sent:\n",
        "        doc = nlp(\" \".join(sent))\n",
        "        temp = []\n",
        "        for token in doc:\n",
        "            #print(type(token))\n",
        "            if token.lemma_ != '-PRON-':\n",
        "                temp.append(token.lemma_)\n",
        "            elif str(token).endswith(\"_char\"):\n",
        "              temp.append(str(token))  \n",
        "            else:\n",
        "                temp.append(str(token))\n",
        "        lemma_sent.append(temp)\n",
        "\n",
        "    # DO NOT REMOVE PRONOUNS, HIM HER ETC.\n",
        "    # Removing stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    stop_words.remove('him')\n",
        "    stop_words.remove('her')\n",
        "    stop_words.remove('hers')\n",
        "    stop_words.remove('his')\n",
        "    stop_words.remove('he')\n",
        "    stop_words.remove('she')\n",
        "    no_stop = []\n",
        "    for sent in lemma_sent:\n",
        "        tokens_without_sw = [word for word in sent if not word in stop_words]\n",
        "        no_stop.append(tokens_without_sw)\n",
        "\n",
        "\n",
        "\n",
        "    # Print previews\n",
        "    if preview:\n",
        "        print('-'*40 + ' Original file samples ' + '-'*40)\n",
        "        print(test_text[:500])\n",
        "        print('-'*40 + ' Sentence samples ' + '-'*40)\n",
        "        for sent in nltk_tokens[:35]: print(sent)\n",
        "        print('-'*35 + ' No punctuation sentence samples ' + '-'*35)\n",
        "        for sent in split_sent[:35]: print(sent)\n",
        "        print('-'*40 + ' Lemma-sentence samples ' + '-'*40)\n",
        "        for sent in lemma_sent[:35]: print(sent)\n",
        "        print('-'*35 + ' No stop words sentence samples ' + '-'*35)\n",
        "        for sent in no_stop[:35]: print(sent)\n",
        "\n",
        "    return no_stop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAC6XiUpx09V"
      },
      "source": [
        "# Clean all stories and save them in a pickle format\n",
        "file_list = os.listdir(PATH + 'final_recoded_corpus')\n",
        "print(len(file_list))\n",
        "for idx, file in enumerate(file_list):\n",
        "    # Opening file\n",
        "    print(file)\n",
        "    print(idx)\n",
        "    txt = open(PATH + 'final_recoded_corpus/'+file, \"r\").read()\n",
        "    \n",
        "    # Saving in pickle to keep list structure\n",
        "    p.dump( clean_text(txt), open(PATH + 'cleaned_corpus/'+file[:-12] + \".p\", \"wb\" ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29qJQwKMx09W"
      },
      "source": [
        "# Compass\n",
        "\n",
        "We create the compass, that is to say a concatenation of all the books. Compass file is saved in the folder \"CADE\".\n",
        "\n",
        "We use the compass to train word2vec in order to get a general semantic space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42A5W66Vx09W"
      },
      "source": [
        "compass = ''\n",
        "clean_compass = []\n",
        "file_list = os.listdir(PATH + 'cleaned_corpus')\n",
        "\n",
        "for idx, file in enumerate(file_list):\n",
        "    print(\"currently processing \" + file)\n",
        "    print(idx)\n",
        "    \n",
        "    # Get corpus name\n",
        "    # story_name = complete_df.loc[index].title + '.p'\n",
        "\n",
        "    # Load file\n",
        "    # print(\"opening pickled file\" + file)\n",
        "    sentence_list = p.load(open( PATH + 'cleaned_corpus/' + file, \"rb\" ))\n",
        "    \n",
        "    temp = []\n",
        "    \n",
        "    # Joining all sentences to make a single plaintext file\n",
        "    for sentence in sentence_list:\n",
        "        #print(sentence)\n",
        "        temp.append(\" \".join(sentence))\n",
        "\n",
        "    final = \" \".join(temp)\n",
        "    clean_compass.append(sentence_list)\n",
        "    \n",
        "    # Saving individual stories\n",
        "    #if index < 10:\n",
        "    text_file = open(PATH + \"CADE/training/\"+ file[:-2] +\".txt\", \"w\")\n",
        "    #else:\n",
        "        #text_file = open(PATH + \"CADE/training/corpus_\"+str(index)+\".txt\", \"w\")\n",
        "        \n",
        "    text_file.write(\" \".join(temp))\n",
        "    text_file.close()\n",
        "    \n",
        "    # Adding corpus to compass\n",
        "    compass += final\n",
        "    \n",
        "# Saving the Compass\n",
        "text_file = open(PATH + \"CADE/compass.txt\", \"w\")\n",
        "text_file.write(compass)\n",
        "text_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqw0v6GNx09X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9298762f-7959-4448-affb-02b87565183e"
      },
      "source": [
        "train = []\n",
        "for i in clean_compass:\n",
        "    for e in i:\n",
        "        train.append(e)\n",
        "    \n",
        "len(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "284537"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSG_YAfLYcjP"
      },
      "source": [
        "## Word2Vec training on Compass\n",
        "\n",
        "The model is saved either in the folder \"skipgram\" or \"CBOW\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvEpofBDx09Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f66c2c46-374e-4d6b-e92d-f1a7b83615eb"
      },
      "source": [
        "# Params for save file\n",
        "\n",
        "\n",
        "\n",
        "# train model\n",
        "# sg default 0 = CBOW; 1 = skipgram\n",
        "model = Word2Vec(train, \n",
        "                     min_count = min_count,\n",
        "                     window=window, \n",
        "                     size=size,\n",
        "                     alpha=0.01,\n",
        "                     sg=model_type, \n",
        "                     #min_alpha=0.0007,  \n",
        "                     negative=10) # 10^-4\n",
        "\n",
        "# summarize the loaded model\n",
        "print(model)\n",
        "\n",
        "# summarize vocabulary\n",
        "words = list(model.wv.vocab)\n",
        "print(\"\\nVocabulary (first 50): \\n\", words[:50])\n",
        "\n",
        "# model folder\n",
        "model_folder = ''\n",
        "if model_type:\n",
        "    model_folder = 'skipgram'\n",
        "else:\n",
        "    model_folder = 'CBOW'\n",
        "\n",
        "# save model\n",
        "model.save(PATH + model_folder+'/model_'+str(min_count)+'_'+str(size)+'.bin')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=16822, size=50, alpha=0.01)\n",
            "\n",
            "Vocabulary (first 50): \n",
            " ['together', 'year', 'call', 'bad', 'lad', 'joke', 'mischief', 'maker', 'pest', 'never', 'cause', 'proper', 'trouble', 'least', 'till', 'autumn', 'round', 'time', 'turn', '13', 'klaus_vogel_almond_char', 'come', 'regular', 'tonto', 'court', 'dan', 'digby', 'spark', 'twins', 'fred', 'frank', 'fill', 'felling', 'go', 'st', 'john', 'joe_gillespie_almond_char', 'old', 'rest', 'us', 'keep', 'bit', 'apart', 'leader', 'great', 'long', 'curl', 'collar', 'wear', 'fade']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/smart_open/smart_open_lib.py:410: UserWarning:\n",
            "\n",
            "This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRk7UkoKdpNf"
      },
      "source": [
        "## Inspecting the vocab and loading the model\n",
        "\n",
        "We can inspect the vocabulary of the model that we have trained on the compass.\n",
        "\n",
        "Moreover, we load the model (twice). We will need it for the form-meaning mapping functions.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtXBcPuWOQGB"
      },
      "source": [
        "#print(\"\\nVocabulary (first 50): \\n\", words[:500])\n",
        "\n",
        "clean_compass_model = Word2Vec.load(PATH + \"skipgram/model_5_50.bin\")\n",
        "compass_model = Word2Vec.load(PATH + \"skipgram/model_5_50.bin\")\n",
        "\n",
        "words = list(compass_model.wv.vocab)\n",
        "#print(len(words))\n",
        "#print(words[:50])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x1B49Xnx09X"
      },
      "source": [
        "## MEN benchmark on Compass\n",
        "SpearmanrResults:\n",
        "1.   correlation=0.4004791629689339\n",
        "2.   pvalue=1.2052347801339114e-96\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FXHc5hzx09Z"
      },
      "source": [
        "# benchmark dataframe\n",
        "spear_df = pd.DataFrame(columns=(['model', 'vocab_size', 'spearmanr_corr', 'spearmanr_p']))\n",
        "\n",
        "# Importing MEN dataset\n",
        "dataset = open(PATH + \"MEN/MEN_dataset_lemma_form_full\", \"r\").read()\n",
        "dataset = dataset.split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT8pEkw4KwPJ",
        "outputId": "bb8646b7-32f8-4f04-a511-1dfd657fdc75"
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sun-n sunlight-n 50.000000', 'automobile-n car-n 50.000000', 'river-n water-n 49.000000', 'stair-n staircase-n 49.000000', 'morning-n sunrise-n 49.000000', 'rain-n storm-n 49.000000', 'cat-n kitten-n 49.000000', 'dance-n dancer-n 49.000000', 'camera-n photography-n 49.000000', 'cat-n feline-j 48.000000', 'sunny-j sunshine-n 48.000000', 'pregnancy-n pregnant-j 48.000000', 'beach-n sand-n 48.000000', 'bakery-n bread-n 48.000000', 'flower-n garden-n 48.000000', 'grass-n lawn-n 48.000000', 'copper-n metal-n 48.000000', 'photo-n photography-n 47.000000', 'cemetery-n graveyard-n 47.000000', 'gravestone-n graveyard-n 47.000000', 'sun-n sunshine-n 47.000000', 'black-j dark-j 47.000000', 'cathedral-n church-n 47.000000', 'frozen-j ice-n 47.000000', 'station-n subway-n 47.000000', 'child-n kid-n 46.000000', 'aquarium-n fish-n 46.000000', 'light-n lighting-n 46.000000', 'fungus-n mushroom-n 46.000000', 'frost-n snow-n 46.000000', 'burn-v flame-n 46.000000', 'ocean-n sea-n 46.000000', 'candy-n chocolate-n 46.000000', 'car-n vehicle-n 46.000000', 'concert-n music-n 46.000000', 'photo-n picture-n 46.000000', 'grape-n wine-n 46.000000', 'bath-n bathroom-n 46.000000', 'bud-n flower-n 46.000000', 'cat-n kitty-n 46.000000', 'ocean-n water-n 46.000000', 'aircraft-n airplane-n 46.000000', 'butterfly-n caterpillar-n 46.000000', 'hair-n wig-n 46.000000', 'blossom-n bud-n 46.000000', 'highway-n road-n 46.000000', 'bunny-n rabbit-n 46.000000', 'bread-n sandwich-n 46.000000', 'mist-n misty-j 46.000000', 'flower-n petal-n 46.000000', 'airplane-n flight-n 46.000000', 'fish-n fishing-n 46.000000', 'ice-n snow-n 46.000000', 'bright-j sun-n 45.000000', 'shade-n tree-n 45.000000', 'bicycle-n bike-n 45.000000', 'truck-n vehicle-n 45.000000', 'shore-n water-n 45.000000', 'boat-n fishing-n 45.000000', 'dog-n puppy-n 45.000000', 'bride-n wedding-n 45.000000', 'bird-n hummingbird-n 45.000000', 'sea-n water-n 45.000000', 'cow-n milk-n 45.000000', 'bird-n feather-n 45.000000', 'skate-n skating-n 45.000000', 'chapel-n church-n 45.000000', 'branch-n twig-n 45.000000', 'concert-n musician-n 45.000000', 'clothes-n dress-n 45.000000', 'automobile-n vehicle-n 45.000000', 'splash-n swimming-n 45.000000', 'bed-n furniture-n 45.000000', 'aircraft-n flight-n 45.000000', 'reptile-n snake-n 45.000000', 'motorcycle-n scooter-n 45.000000', 'coffee-n tea-n 45.000000', 'feather-n goose-n 45.000000', 'pool-n swimming-n 45.000000', 'eye-n face-n 45.000000', 'dirt-n dirty-j 45.000000', 'railway-n train-n 45.000000', 'harbour-n port-n 45.000000', 'fruit-n strawberry-n 45.000000', 'flight-n plane-n 45.000000', 'smoke-n smoking-n 45.000000', 'ivy-n plant-n 45.000000', 'river-n stream-n 45.000000', 'lake-n water-n 45.000000', 'kitten-n kitty-n 45.000000', 'snow-n snowman-n 45.000000', 'dog-n terrier-n 45.000000', 'daffodil-n flower-n 45.000000', 'pond-n water-n 45.000000', 'show-n television-n 44.000000', 'handwriting-n write-v 44.000000', 'flood-n water-n 44.000000', 'jazz-n musician-n 44.000000', 'eagle-n feather-n 44.000000', 'grape-n vine-n 44.000000', 'bird-n hawk-n 44.000000', 'clothes-n outfit-n 44.000000', 'exhibition-n museum-n 44.000000', 'hand-n palm-n 44.000000', 'grave-n graveyard-n 44.000000', 'berry-n strawberry-n 44.000000', 'forest-n oak-n 44.000000', 'crochet-n knit-v 44.000000', 'bird-n eagle-n 44.000000', 'canine-j puppy-n 44.000000', 'bar-n cocktail-n 44.000000', 'bar-n pub-n 44.000000', 'sunlight-n sunshine-n 44.000000', 'apple-n fruit-n 44.000000', 'sun-n sunrise-n 44.000000', 'gymnastics-n sport-n 44.000000', 'sailing-n ship-n 44.000000', 'beach-n sea-n 44.000000', 'game-n hockey-n 44.000000', 'bed-n pillow-n 44.000000', 'daffodil-n tulip-n 44.000000', 'flower-n plant-n 44.000000', 'fire-n smoke-n 44.000000', 'canine-j dog-n 44.000000', 'bracelet-n jewelry-n 44.000000', 'feline-j kitty-n 44.000000', 'architecture-n building-n 44.000000', 'shop-n shopping-n 44.000000', 'highway-n traffic-n 44.000000', 'lizard-n reptile-n 44.000000', 'music-n piano-n 44.000000', 'strawberry-n sweet-j 44.000000', 'snow-n winter-n 44.000000', 'autumn-n spring-n 44.000000', 'bacon-n meat-n 44.000000', 'raspberry-n strawberry-n 44.000000', 'chipmunk-n squirrel-n 44.000000', 'coast-n harbor-n 44.000000', 'dress-n skirt-n 44.000000', 'sun-n sunny-j 44.000000', 'lily-n tulip-n 44.000000', 'grave-n gravestone-n 44.000000', 'bright-j sunny-j 44.000000', 'dandelion-n plant-n 44.000000', 'light-n sunlight-n 44.000000', 'hill-n mountain-n 43.000000', 'burger-n food-n 43.000000', 'sea-n shore-n 43.000000', 'feather-n peacock-n 43.000000', 'child-n mother-n 43.000000', 'night-n sunset-n 43.000000', 'orange-j peel-n 43.000000', 'subway-n train-n 43.000000', 'camera-n lens-n 43.000000', 'daisy-n petal-n 43.000000', 'aircraft-n wing-n 43.000000', 'bloom-n flower-n 43.000000', 'clothes-n jacket-n 43.000000', 'dinner-n restaurant-n 43.000000', 'swim-v swimming-n 43.000000', 'cemetery-n gravestone-n 43.000000', 'cigarette-n smoke-n 43.000000', 'shirt-n skirt-n 43.000000', 'baby-n pregnant-j 43.000000', 'cherry-n fruit-n 43.000000', 'beef-n meat-n 43.000000', 'blossom-n daffodil-n 43.000000', 'bloom-n blossom-n 43.000000', 'maple-n oak-n 43.000000', 'frost-n winter-n 43.000000', 'colour-n pink-j 43.000000', 'dog-n poodle-n 43.000000', 'lantern-n light-n 43.000000', 'coast-n sea-n 43.000000', 'tunnel-n underground-j 43.000000', 'dog-n pet-n 43.000000', 'hair-n haircut-n 43.000000', 'day-n sunset-n 43.000000', 'bikini-n swimsuit-n 43.000000', 'rail-n railway-n 43.000000', 'art-n museum-n 43.000000', 'painting-n portrait-n 43.000000', 'dress-n wedding-n 43.000000', 'poodle-n puppy-n 43.000000', 'port-n ship-n 43.000000', 'bloom-n tulip-n 43.000000', 'cold-j winter-n 43.000000', 'bakery-n cake-n 43.000000', 'building-n roof-n 43.000000', 'iron-n steel-n 43.000000', 'bird-n stork-n 43.000000', 'lily-n plant-n 43.000000', 'eat-v food-n 43.000000', 'bathroom-n kitchen-n 43.000000', 'jazz-n music-n 43.000000', 'fabric-n wool-n 43.000000', 'aquarium-n tank-n 43.000000', 'fire-n flame-n 43.000000', 'bloom-n rose-n 43.000000', 'leaf-n nature-n 43.000000', 'town-n village-n 43.000000', 'apple-n orange-j 43.000000', 'dawn-n sunrise-n 43.000000', 'engine-n gasoline-n 43.000000', 'oak-n tree-n 43.000000', 'guitar-n piano-n 43.000000', 'chocolate-n dessert-n 43.000000', 'cat-n paw-n 43.000000', 'bird-n goose-n 43.000000', 'blue-j sky-n 43.000000', 'pool-n swim-v 43.000000', 'bracelet-n necklace-n 42.000000', 'fruit-n salad-n 42.000000', 'egg-n nest-n 42.000000', 'boat-n sailing-n 42.000000', 'bird-n crow-n 42.000000', 'bird-n flamingo-n 42.000000', 'day-n sunshine-n 42.000000', 'hockey-n sport-n 42.000000', 'burger-n eat-v 42.000000', 'fruit-n raspberry-n 42.000000', 'lunch-n sandwich-n 42.000000', 'foot-n toe-n 42.000000', 'baby-n mother-n 42.000000', 'amphibian-n frog-n 42.000000', 'burn-v fire-n 42.000000', 'hockey-n ice-n 42.000000', 'cold-j frozen-j 42.000000', 'oak-n wood-n 42.000000', 'photographer-n photography-n 42.000000', 'man-n woman-n 42.000000', 'hair-n redhead-n 42.000000', 'harbor-n port-n 42.000000', 'pug-n puppy-n 42.000000', 'sunrise-n sunset-n 42.000000', 'leather-n shoe-n 42.000000', 'beach-n shore-n 42.000000', 'color-n red-j 42.000000', 'paint-v painting-n 42.000000', 'storm-n wind-n 42.000000', 'color-n violet-n 42.000000', 'rain-n wet-j 42.000000', 'diner-n eat-v 42.000000', 'bed-n bedroom-n 42.000000', 'guitar-n musician-n 42.000000', 'petal-n rose-n 42.000000', 'rail-n subway-n 42.000000', 'holiday-n vacation-n 42.000000', 'bed-n sleep-v 42.000000', 'cigarette-n smoking-n 42.000000', 'airplane-n plane-n 42.000000', 'daffodil-n plant-n 42.000000', 'diner-n kitchen-n 42.000000', 'coin-n silver-n 42.000000', 'cake-n chocolate-n 42.000000', 'evening-n night-n 42.000000', 'race-n racing-n 42.000000', 'flight-n fly-v 42.000000', 'face-n lip-n 42.000000', 'berry-n raspberry-n 42.000000', 'lamp-n light-n 42.000000', 'bird-n nest-n 42.000000', 'mother-n pregnant-j 42.000000', 'animal-n pet-n 42.000000', 'butterfly-n insect-n 42.000000', 'sky-n sunrise-n 42.000000', 'canine-j husky-n 42.000000', 'food-n meat-n 42.000000', 'cloud-n sky-n 42.000000', 'crow-n feather-n 42.000000', 'blossom-n flower-n 42.000000', 'splash-n swim-v 42.000000', 'band-n musician-n 42.000000', 'cactus-n plant-n 42.000000', 'eagle-n hawk-n 42.000000', 'harbour-n sea-n 42.000000', 'flower-n foliage-n 42.000000', 'red-j violet-n 42.000000', 'music-n sing-v 42.000000', 'breakfast-n morning-n 42.000000', 'cafe-n restaurant-n 42.000000', 'beach-n coast-n 42.000000', 'puddle-n splash-n 42.000000', 'bird-n pelican-n 42.000000', 'clothes-n sock-n 42.000000', 'amphibian-n lizard-n 41.000000', 'daughter-n son-n 41.000000', 'car-n motor-n 41.000000', 'amphibian-n reptile-n 41.000000', 'day-n morning-n 41.000000', 'aircraft-n fly-v 41.000000', 'airplane-n airport-n 41.000000', 'metro-n train-n 41.000000', 'band-n music-n 41.000000', 'shadow-n sunlight-n 41.000000', 'night-n sleep-v 41.000000', 'salad-n soup-n 41.000000', 'porch-n roof-n 41.000000', 'eye-n tear-n 41.000000', 'colour-n rainbow-n 41.000000', 'berry-n fruit-n 41.000000', 'red-j yellow-j 41.000000', 'sock-n stocking-n 41.000000', 'flamingo-n hummingbird-n 41.000000', 'tree-n twig-n 41.000000', 'kiss-n lip-n 41.000000', 'burger-n sandwich-n 41.000000', 'pregnant-j woman-n 41.000000', 'rain-n weather-n 41.000000', 'dinner-n eat-v 41.000000', 'feather-n hawk-n 41.000000', 'animal-n zoo-n 41.000000', 'duck-n mallard-n 41.000000', 'mountain-n valley-n 41.000000', 'beach-n harbour-n 41.000000', 'musician-n rock-n 41.000000', 'band-n guitar-n 41.000000', 'car-n garage-n 41.000000', 'foot-n leg-n 41.000000', 'sky-n sunlight-n 41.000000', 'mist-n rain-n 41.000000', 'mother-n son-n 41.000000', 'airplane-n wing-n 41.000000', 'colour-n red-j 41.000000', 'music-n musician-n 41.000000', 'bay-n beach-n 41.000000', 'blonde-j redhead-n 41.000000', 'petal-n plant-n 41.000000', 'kitchen-n room-n 41.000000', 'lingerie-n sexy-j 41.000000', 'automobile-n parking-n 41.000000', 'bar-n restaurant-n 41.000000', 'bedroom-n room-n 41.000000', 'bus-n taxi-n 41.000000', 'fun-n happy-j 41.000000', 'station-n train-n 41.000000', 'pelican-n stork-n 41.000000', 'black-j grey-j 41.000000', 'orange-j yellow-j 41.000000', 'foliage-n petal-n 41.000000', 'park-n parking-n 41.000000', 'lip-n tongue-n 41.000000', 'fog-n misty-j 41.000000', 'canine-j poodle-n 41.000000', 'bath-n wash-v 41.000000', 'foliage-n tree-n 41.000000', 'panorama-n view-n 41.000000', 'bloom-n daisy-n 41.000000', 'escalator-n stair-n 41.000000', 'petal-n tulip-n 41.000000', 'fishing-n sea-n 41.000000', 'beef-n cattle-n 41.000000', 'noodle-n rice-n 41.000000', 'bird-n parrot-n 41.000000', 'fruit-n orange-j 41.000000', 'mural-n painting-n 41.000000', 'airport-n flight-n 41.000000', 'shopping-n store-n 41.000000', 'summer-n sunny-j 41.000000', 'road-n sidewalk-n 41.000000', 'airplane-n fly-v 41.000000', 'guitar-n music-n 40.000000', 'cat-n whisker-n 40.000000', 'family-n friend-n 40.000000', 'bloom-n petal-n 40.000000', 'musician-n piano-n 40.000000', 'dirty-j wash-v 40.000000', 'elephant-n giraffe-n 40.000000', 'puppy-n terrier-n 40.000000', 'breakfast-n kitchen-n 40.000000', 'subway-n underground-j 40.000000', 'sand-n shore-n 40.000000', 'butterfly-n dragonfly-n 40.000000', 'cheetah-n lion-n 40.000000', 'color-n yellow-j 40.000000', 'door-n lock-v 40.000000', 'bright-j sunlight-n 40.000000', 'van-n vehicle-n 40.000000', 'orange-j red-j 40.000000', 'beetle-n insect-n 40.000000', 'kid-n mom-n 40.000000', 'daughter-n mother-n 40.000000', 'child-n school-n 40.000000', 'giraffe-n zebra-n 40.000000', 'harbor-n harbour-n 40.000000', 'lamb-n sheep-n 40.000000', 'heart-n love-n 40.000000', 'lily-n rose-n 40.000000', 'asphalt-n road-n 40.000000', 'morning-n sunny-j 40.000000', 'coast-n shore-n 40.000000', 'sunny-j sunset-n 40.000000', 'nest-n twig-n 40.000000', 'happy-j smile-n 40.000000', 'figure-n skating-n 40.000000', 'rail-n train-n 40.000000', 'door-n wall-n 40.000000', 'dawn-n sun-n 40.000000', 'feather-n stork-n 40.000000', 'morning-n sunshine-n 40.000000', 'building-n construction-n 40.000000', 'cafe-n coffee-n 40.000000', 'bloom-n bud-n 40.000000', 'jacket-n leather-n 40.000000', 'map-n travel-n 40.000000', 'plant-n seed-n 40.000000', 'city-n metro-n 40.000000', 'pebble-n sand-n 40.000000', 'cafe-n lunch-n 40.000000', 'coast-n harbour-n 40.000000', 'dog-n pug-n 40.000000', 'sky-n sun-n 40.000000', 'mallard-n swan-n 40.000000', 'cloud-n rain-n 40.000000', 'sky-n sunshine-n 40.000000', 'frost-n weather-n 40.000000', 'cherry-n raspberry-n 40.000000', 'downtown-j street-n 40.000000', 'bloom-n dandelion-n 40.000000', 'dragonfly-n insect-n 40.000000', 'bottle-n wine-n 40.000000', 'feel-v happy-j 40.000000', 'railway-n station-n 40.000000', 'beach-n swimming-n 40.000000', 'cafe-n diner-n 40.000000', 'cafe-n pub-n 40.000000', 'building-n tall-j 40.000000', 'burger-n meat-n 40.000000', 'gold-n silver-n 40.000000', 'summer-n weather-n 40.000000', 'military-j soldier-n 40.000000', 'cemetery-n grave-n 40.000000', 'pizza-n restaurant-n 39.000000', 'bright-j colour-n 39.000000', 'canine-j paw-n 39.000000', 'swim-v underwater-j 39.000000', 'sea-n swim-v 39.000000', 'pub-n restaurant-n 39.000000', 'day-n time-n 39.000000', 'canine-j terrier-n 39.000000', 'bottle-n glass-n 39.000000', 'bed-n relax-v 39.000000', 'seed-n sunflower-n 39.000000', 'bird-n owl-n 39.000000', 'art-n sculpture-n 39.000000', 'light-n shade-n 39.000000', 'apartment-n staircase-n 39.000000', 'outfit-n sock-n 39.000000', 'carrot-n potato-n 39.000000', 'lizard-n snake-n 39.000000', 'city-n sidewalk-n 39.000000', 'guitar-n rock-n 39.000000', 'brick-n building-n 39.000000', 'eat-v soup-n 39.000000', 'dew-n misty-j 39.000000', 'blue-j colour-n 39.000000', 'dawn-n morning-n 39.000000', 'cooking-n restaurant-n 39.000000', 'bay-n sea-n 39.000000', 'cafe-n shop-n 39.000000', 'floor-n roof-n 39.000000', 'clothes-n hat-n 39.000000', 'marble-n stone-n 39.000000', 'duck-n goose-n 39.000000', 'collection-n museum-n 39.000000', 'happy-j love-n 39.000000', 'bakery-n shop-n 39.000000', 'mist-n wet-j 39.000000', 'blossom-n petal-n 39.000000', 'bright-j light-n 39.000000', 'rice-n sushi-n 39.000000', 'cooking-n meat-n 39.000000', 'day-n night-n 39.000000', 'kiss-n love-n 39.000000', 'stream-n waterfall-n 39.000000', 'interior-n room-n 39.000000', 'surf-n surfer-n 39.000000', 'poodle-n terrier-n 39.000000', 'cold-j frost-n 39.000000', 'city-n town-n 39.000000', 'ocean-n underwater-j 39.000000', 'harbor-n sailing-n 39.000000', 'scenery-n sunset-n 39.000000', 'green-j violet-n 39.000000', 'harbor-n ship-n 39.000000', 'summer-n sunshine-n 39.000000', 'blue-j grey-j 39.000000', 'art-n graphic-j 39.000000', 'lake-n shore-n 39.000000', 'rust-n rusty-j 39.000000', 'architecture-n design-n 39.000000', 'goose-n swan-n 39.000000', 'architecture-n construction-n 39.000000', 'hawk-n nest-n 39.000000', 'carrot-n salad-n 39.000000', 'fruit-n tomato-n 39.000000', 'purple-j violet-n 39.000000', 'misty-j rain-n 39.000000', 'clothes-n jean-n 39.000000', 'bloom-n daffodil-n 39.000000', 'brick-n construction-n 39.000000', 'diner-n restaurant-n 39.000000', 'ceiling-n roof-n 39.000000', 'paint-v portrait-n 39.000000', 'ripple-n wave-n 39.000000', 'beard-n face-n 39.000000', 'apple-n raspberry-n 39.000000', 'fashion-n outfit-n 39.000000', 'downtown-j skyscraper-n 39.000000', 'bud-n daffodil-n 39.000000', 'harbor-n shore-n 39.000000', 'blonde-j hair-n 39.000000', 'kitten-n paw-n 39.000000', 'bay-n shore-n 39.000000', 'shop-n store-n 39.000000', 'gravestone-n memorial-n 38.000000', 'canine-j pug-n 38.000000', 'crow-n hawk-n 38.000000', 'dress-n outfit-n 38.000000', 'city-n urban-j 38.000000', 'bedroom-n door-n 38.000000', 'bus-n tram-n 38.000000', 'spring-n summer-n 38.000000', 'scenery-n waterfall-n 38.000000', 'road-n traffic-n 38.000000', 'hill-n valley-n 38.000000', 'ceiling-n floor-n 38.000000', 'splash-n water-n 38.000000', 'grass-n weed-n 38.000000', 'sunny-j weather-n 38.000000', 'parrot-n wing-n 38.000000', 'daisy-n violet-n 38.000000', 'copper-n silver-n 38.000000', 'baseball-n hockey-n 38.000000', 'pet-n poodle-n 38.000000', 'blossom-n foliage-n 38.000000', 'pink-j purple-j 38.000000', 'grey-j shade-n 38.000000', 'panorama-n scenery-n 38.000000', 'downtown-j metro-n 38.000000', 'beard-n hair-n 38.000000', 'dandelion-n petal-n 38.000000', 'blue-j violet-n 38.000000', 'daisy-n flower-n 38.000000', 'noodle-n soup-n 38.000000', 'pet-n puppy-n 38.000000', 'bud-n petal-n 38.000000', 'ancient-j ruin-n 38.000000', 'eye-n iris-n 38.000000', 'puddle-n water-n 38.000000', 'harbor-n sea-n 38.000000', 'painting-n sculpture-n 38.000000', 'sand-n sea-n 38.000000', 'feline-j kitten-n 38.000000', 'bird-n swan-n 38.000000', 'baseball-n game-n 38.000000', 'colour-n purple-j 38.000000', 'pool-n splash-n 38.000000', 'cattle-n sheep-n 38.000000', 'landscape-n scenery-n 38.000000', 'coin-n gold-n 38.000000', 'boat-n shore-n 38.000000', 'skyscraper-n tall-j 38.000000', 'apple-n cherry-n 38.000000', 'beef-n chicken-n 38.000000', 'hot-j sunny-j 38.000000', 'dessert-n fruit-n 38.000000', 'photographer-n portrait-n 38.000000', 'chicken-n meat-n 38.000000', 'ceiling-n interior-n 38.000000', 'bathroom-n bedroom-n 38.000000', 'hummingbird-n stork-n 38.000000', 'motor-n vehicle-n 38.000000', 'colour-n grey-j 38.000000', 'blue-j orange-j 38.000000', 'dawn-n dusk-n 38.000000', 'building-n downtown-j 38.000000', 'face-n tear-n 38.000000', 'boat-n harbour-n 38.000000', 'cattle-n farm-n 38.000000', 'drip-v wet-j 38.000000', 'brown-j green-j 38.000000', 'bedroom-n ceiling-n 38.000000', 'bread-n eat-v 38.000000', 'dinner-n evening-n 38.000000', 'face-n smile-n 38.000000', 'bride-n dress-n 38.000000', 'stone-n wall-n 38.000000', 'mural-n paint-v 38.000000', 'foliage-n plant-n 38.000000', 'day-n dusk-n 38.000000', 'roof-n wall-n 38.000000', 'cooking-n food-n 38.000000', 'photography-n portrait-n 38.000000', 'bud-n foliage-n 38.000000', 'lily-n pond-n 37.000000', 'harbour-n shore-n 37.000000', 'palm-n tree-n 37.000000', 'bus-n subway-n 37.000000', 'holiday-n travel-n 37.000000', 'skyline-n view-n 37.000000', 'bedroom-n cottage-n 37.000000', 'dinner-n lunch-n 37.000000', 'grave-n memorial-n 37.000000', 'dessert-n sweet-j 37.000000', 'bird-n insect-n 37.000000', 'concert-n rock-n 37.000000', 'mushroom-n tomato-n 37.000000', 'metro-n railway-n 37.000000', 'giraffe-n zoo-n 37.000000', 'railway-n subway-n 37.000000', 'misty-j weather-n 37.000000', 'parrot-n pelican-n 37.000000', 'bedroom-n sleep-v 37.000000', 'autumn-n summer-n 37.000000', 'automobile-n truck-n 37.000000', 'amphibian-n mammal-n 37.000000', 'cemetery-n memorial-n 37.000000', 'orange-j purple-j 37.000000', 'blue-j color-n 37.000000', 'daffodil-n rose-n 37.000000', 'berry-n seed-n 37.000000', 'hummingbird-n mallard-n 37.000000', 'dandelion-n grass-n 37.000000', 'brick-n concrete-j 37.000000', 'costume-n dress-n 37.000000', 'cloud-n mist-n 37.000000', 'sea-n tropical-j 37.000000', 'brown-j grey-j 37.000000', 'bathroom-n room-n 37.000000', 'daisy-n plant-n 37.000000', 'paint-v picture-n 37.000000', 'eye-n lip-n 37.000000', 'autumn-n winter-n 37.000000', 'drip-v rain-n 37.000000', 'horizon-n sky-n 37.000000', 'black-j blue-j 37.000000', 'metro-n station-n 37.000000', 'alley-n street-n 37.000000', 'child-n family-n 37.000000', 'mountain-n scenery-n 37.000000', 'concrete-j construction-n 37.000000', 'mill-n windmill-n 37.000000', 'summer-n winter-n 37.000000', 'plant-n twig-n 37.000000', 'breakfast-n lunch-n 37.000000', 'concrete-j floor-n 37.000000', 'rain-n sky-n 37.000000', 'food-n frozen-j 37.000000', 'moss-n plant-n 37.000000', 'flower-n spring-n 37.000000', 'bird-n mallard-n 37.000000', 'graphic-j illustration-n 37.000000', 'eat-v fruit-n 37.000000', 'ceiling-n porch-n 37.000000', 'river-n valley-n 37.000000', 'fog-n mist-n 37.000000', 'dude-n guy-n 37.000000', 'moon-n sky-n 37.000000', 'bar-n sushi-n 37.000000', 'beauty-n scenery-n 37.000000', 'feather-n mallard-n 37.000000', 'furniture-n patio-n 37.000000', 'light-n shadow-n 37.000000', 'bay-n harbour-n 37.000000', 'wash-v water-n 37.000000', 'flight-n owl-n 37.000000', 'paw-n whisker-n 37.000000', 'costume-n wig-n 37.000000', 'animal-n giraffe-n 37.000000', 'autumn-n foliage-n 37.000000', 'animal-n cattle-n 37.000000', 'building-n skyscraper-n 37.000000', 'ice-n skating-n 37.000000', 'meat-n potato-n 37.000000', 'bud-n twig-n 37.000000', 'knit-v stitch-n 37.000000', 'hot-j sunshine-n 37.000000', 'bed-n room-n 37.000000', 'music-n rock-n 37.000000', 'cooking-n rice-n 37.000000', 'berry-n cherry-n 37.000000', 'piano-n play-v 37.000000', 'flower-n lily-n 37.000000', 'cherry-n strawberry-n 37.000000', 'clothes-n skirt-n 37.000000', 'art-n painting-n 37.000000', 'bird-n gull-n 37.000000', 'spiral-n staircase-n 37.000000', 'paw-n pet-n 37.000000', 'feather-n nest-n 37.000000', 'feather-n owl-n 37.000000', 'blossom-n cherry-n 37.000000', 'goat-n sheep-n 37.000000', 'green-j pink-j 37.000000', 'foliage-n garden-n 37.000000', 'dog-n husky-n 37.000000', 'feather-n hummingbird-n 37.000000', 'sunshine-n weather-n 37.000000', 'snow-n weather-n 37.000000', 'surfer-n wave-n 37.000000', 'breakfast-n dinner-n 37.000000', 'shoe-n toe-n 37.000000', 'band-n play-v 37.000000', 'coffee-n mug-n 37.000000', 'brick-n wall-n 37.000000', 'fishing-n sailing-n 37.000000', 'grey-j white-j 37.000000', 'orange-j strawberry-n 37.000000', 'color-n purple-j 37.000000', 'blossom-n daisy-n 37.000000', 'hawk-n owl-n 37.000000', 'exhibition-n photography-n 37.000000', 'morning-n night-n 37.000000', 'band-n concert-n 37.000000', 'dress-n shirt-n 37.000000', 'river-n waterfall-n 37.000000', 'ceramic-j tile-n 36.000000', 'cloud-n droplet-n 36.000000', 'exhibition-n sculpture-n 36.000000', 'oak-n twig-n 36.000000', 'movie-n television-n 36.000000', 'butterfly-n hummingbird-n 36.000000', 'daisy-n grass-n 36.000000', 'floor-n marble-n 36.000000', 'canyon-n river-n 36.000000', 'decoration-n interior-n 36.000000', 'flamingo-n stork-n 36.000000', 'bear-v mother-n 36.000000', 'moon-n sun-n 36.000000', 'musician-n sing-v 36.000000', 'green-j red-j 36.000000', 'purple-j white-j 36.000000', 'canine-j pet-n 36.000000', 'morning-n sleep-v 36.000000', 'weather-n winter-n 36.000000', 'sky-n sunny-j 36.000000', 'jacket-n sock-n 36.000000', 'blue-j red-j 36.000000', 'green-j grey-j 36.000000', 'lily-n petal-n 36.000000', 'blue-j purple-j 36.000000', 'goose-n mallard-n 36.000000', 'hotel-n restaurant-n 36.000000', 'downtown-j urban-j 36.000000', 'jean-n skirt-n 36.000000', 'guy-n people-n 36.000000', 'birthday-n happy-j 36.000000', 'chicken-n soup-n 36.000000', 'fly-v wing-n 36.000000', 'door-n room-n 36.000000', 'skyline-n skyscraper-n 36.000000', 'cheetah-n giraffe-n 36.000000', 'feline-j pet-n 36.000000', 'car-n parking-n 36.000000', 'gull-n mallard-n 36.000000', 'spring-n winter-n 36.000000', 'daffodil-n spring-n 36.000000', 'building-n skyline-n 36.000000', 'salad-n tomato-n 36.000000', 'book-n write-v 36.000000', 'bucket-n water-n 36.000000', 'lady-n sexy-j 36.000000', 'ceiling-n room-n 36.000000', 'puddle-n rain-n 36.000000', 'costume-n outfit-n 36.000000', 'hill-n scenery-n 36.000000', 'bacon-n chicken-n 36.000000', 'dawn-n night-n 36.000000', 'cocktail-n restaurant-n 36.000000', 'daffodil-n petal-n 36.000000', 'canyon-n valley-n 36.000000', 'brick-n house-n 36.000000', 'band-n rock-n 36.000000', 'book-n illustration-n 36.000000', 'desk-n sit-v 36.000000', 'bright-j sky-n 36.000000', 'autumn-n sunny-j 36.000000', 'colour-n yellow-j 36.000000', 'cold-j weather-n 36.000000', 'blue-j green-j 36.000000', 'glitter-v sunlight-n 36.000000', 'drip-v water-n 36.000000', 'day-n misty-j 36.000000', 'food-n noodle-n 36.000000', 'goat-n milk-n 36.000000', 'pink-j yellow-j 36.000000', 'floor-n interior-n 36.000000', 'black-j purple-j 36.000000', 'door-n window-n 36.000000', 'city-n skyline-n 36.000000', 'bear-v live-v 35.000000', 'art-n work-n 35.000000', 'pink-j violet-n 35.000000', 'bath-n room-n 35.000000', 'dew-n rain-n 35.000000', 'boy-n girl-n 35.000000', 'canyon-n mountain-n 35.000000', 'white-j yellow-j 35.000000', 'colour-n shade-n 35.000000', 'banana-n cherry-n 35.000000', 'mammal-n rodent-n 35.000000', 'explosion-n fire-n 35.000000', 'shore-n swim-v 35.000000', 'cloud-n misty-j 35.000000', 'sit-v stand-v 35.000000', 'glitter-v gold-n 35.000000', 'black-j white-j 35.000000', 'light-n neon-n 35.000000', 'machine-n wash-v 35.000000', 'coffee-n dinner-n 35.000000', 'feather-n flamingo-n 35.000000', 'downtown-j sidewalk-n 35.000000', 'cooking-n eat-v 35.000000', 'feline-j paw-n 35.000000', 'crow-n gull-n 35.000000', 'festival-n music-n 35.000000', 'dirt-n road-n 35.000000', 'gull-n pelican-n 35.000000', 'carrot-n tomato-n 35.000000', 'blossom-n tree-n 35.000000', 'restaurant-n shop-n 35.000000', 'cherry-n grape-n 35.000000', 'automobile-n racing-n 35.000000', 'jazz-n piano-n 35.000000', 'hawk-n pelican-n 35.000000', 'baseball-n play-v 35.000000', 'bloom-n plant-n 35.000000', 'ceiling-n wall-n 35.000000', 'beef-n potato-n 35.000000', 'breakfast-n restaurant-n 35.000000', 'black-j colour-n 35.000000', 'bright-j glitter-v 35.000000', 'hummingbird-n nest-n 35.000000', 'feline-j whisker-n 35.000000', 'beach-n holiday-n 35.000000', 'sailing-n shore-n 35.000000', 'design-n graphic-j 35.000000', 'music-n track-n 35.000000', 'air-n cold-j 35.000000', 'dessert-n eat-v 35.000000', 'chocolate-n strawberry-n 35.000000', 'dinner-n night-n 35.000000', 'dusk-n sunrise-n 35.000000', 'boat-n sink-v 35.000000', 'beef-n cooking-n 35.000000', 'jacket-n jean-n 35.000000', 'computer-n lab-n 35.000000', 'downtown-j skyline-n 35.000000', 'fun-n game-n 35.000000', 'ivy-n tree-n 35.000000', 'nest-n wasp-n 35.000000', 'garden-n pumpkin-n 35.000000', 'curl-v haircut-n 35.000000', 'eat-v meat-n 35.000000', 'outfit-n skirt-n 35.000000', 'bacon-n beef-n 35.000000', 'skyscraper-n tower-n 35.000000', 'splash-n wash-v 35.000000', 'daffodil-n foliage-n 34.000000', 'garden-n patio-n 34.000000', 'metro-n subway-n 34.000000', 'beach-n scenery-n 34.000000', 'photographer-n wedding-n 34.000000', 'floor-n room-n 34.000000', 'purple-j yellow-j 34.000000', 'guitar-n sing-v 34.000000', 'petal-n yellow-j 34.000000', 'bead-n necklace-n 34.000000', 'black-j brown-j 34.000000', 'dessert-n strawberry-n 34.000000', 'beef-n lamb-n 34.000000', 'bread-n potato-n 34.000000', 'fishing-n harbour-n 34.000000', 'pug-n terrier-n 34.000000', 'evening-n time-n 34.000000', 'office-n table-n 34.000000', 'cat-n lick-v 34.000000', 'building-n interior-n 34.000000', 'crochet-n stitch-n 34.000000', 'spring-n sunshine-n 34.000000', 'concert-n jazz-n 34.000000', 'cooking-n soup-n 34.000000', 'shade-n sun-n 34.000000', 'tall-j tower-n 34.000000', 'pepper-n salad-n 34.000000', 'strawberry-n tomato-n 34.000000', 'fruit-n peel-n 34.000000', 'scenery-n skyline-n 34.000000', 'green-j yellow-j 34.000000', 'brown-j orange-j 34.000000', 'colour-n orange-j 34.000000', 'harbour-n ship-n 34.000000', 'violet-n yellow-j 34.000000', 'sport-n swimming-n 34.000000', 'friend-n happy-j 34.000000', 'blue-j pink-j 34.000000', 'blossom-n orange-j 34.000000', 'rail-n station-n 34.000000', 'potato-n salad-n 34.000000', 'interior-n wall-n 34.000000', 'hawk-n hummingbird-n 34.000000', 'cliff-n coast-n 34.000000', 'feather-n wing-n 34.000000', 'brown-j yellow-j 34.000000', 'raspberry-n sweet-j 34.000000', 'concert-n sing-v 34.000000', 'art-n craft-n 34.000000', 'bloom-n foliage-n 34.000000', 'chicken-n rice-n 34.000000', 'cherry-n orange-j 34.000000', 'blossom-n fruit-n 34.000000', 'animal-n wild-j 34.000000', 'line-n railway-n 34.000000', 'roof-n tile-n 34.000000', 'concert-n piano-n 34.000000', 'potato-n rice-n 34.000000', 'cloud-n sunshine-n 34.000000', 'marble-n statue-n 34.000000', 'frozen-j meat-n 34.000000', 'band-n punk-n 34.000000', 'insect-n reptile-n 34.000000', 'building-n staircase-n 34.000000', 'bed-n breakfast-n 34.000000', 'bloom-n lily-n 34.000000', 'blonde-j girl-n 34.000000', 'jean-n outfit-n 34.000000', 'bread-n cooking-n 34.000000', 'flower-n violet-n 34.000000', 'peel-n skin-n 34.000000', 'dessert-n diner-n 34.000000', 'art-n exhibition-n 34.000000', 'jacket-n shirt-n 34.000000', 'brown-j purple-j 34.000000', 'floor-n patio-n 34.000000', 'downtown-j highway-n 34.000000', 'purple-j red-j 34.000000', 'dragonfly-n frog-n 33.000000', 'mammal-n monkey-n 33.000000', 'mist-n morning-n 33.000000', 'feather-n gull-n 33.000000', 'gull-n stork-n 33.000000', 'dusk-n morning-n 33.000000', 'guitar-n play-v 33.000000', 'bloom-n violet-n 33.000000', 'mallard-n stork-n 33.000000', 'band-n piano-n 33.000000', 'glitter-v sky-n 33.000000', 'orange-j pink-j 33.000000', 'potato-n soup-n 33.000000', 'grey-j violet-n 33.000000', 'construction-n demolition-n 33.000000', 'scenery-n valley-n 33.000000', 'morning-n sky-n 33.000000', 'beach-n cliff-n 33.000000', 'storm-n tropical-j 33.000000', 'black-j pink-j 33.000000', 'hat-n jacket-n 33.000000', 'dragonfly-n hummingbird-n 33.000000', 'pink-j white-j 33.000000', 'blue-j yellow-j 33.000000', 'cold-j hot-j 33.000000', 'flower-n pink-j 33.000000', 'bright-j star-n 33.000000', 'restaurant-n sushi-n 33.000000', 'guitar-n keyboard-n 33.000000', 'diner-n sushi-n 33.000000', 'furniture-n room-n 33.000000', 'desert-n scenery-n 33.000000', 'cafe-n dinner-n 33.000000', 'bakery-n cafe-n 33.000000', 'flamingo-n pelican-n 33.000000', 'salad-n sandwich-n 33.000000', 'bright-j dark-j 33.000000', 'building-n floor-n 33.000000', 'bacon-n eat-v 33.000000', 'apartment-n floor-n 33.000000', 'railway-n underground-j 33.000000', 'lip-n smile-n 33.000000', 'fungus-n plant-n 33.000000', 'breakfast-n diner-n 33.000000', 'feather-n pelican-n 33.000000', 'bath-n hot-j 33.000000', 'arch-n roof-n 33.000000', 'game-n match-n 33.000000', 'metro-n rail-n 33.000000', 'decoration-n wood-n 33.000000', 'building-n demolition-n 33.000000', 'art-n collage-n 33.000000', 'ship-n sink-v 33.000000', 'grey-j purple-j 33.000000', 'garden-n lawn-n 33.000000', 'orange-j violet-n 33.000000', 'ivy-n oak-n 33.000000', 'dog-n lick-v 33.000000', 'dawn-n sunny-j 33.000000', 'fun-n kid-n 33.000000', 'lunch-n restaurant-n 33.000000', 'metro-n underground-j 33.000000', 'eat-v strawberry-n 33.000000', 'foliage-n rose-n 33.000000', 'evening-n sleep-v 33.000000', 'construction-n interior-n 33.000000', 'weather-n wet-j 33.000000', 'fruit-n nut-n 33.000000', 'car-n park-n 33.000000', 'ink-n pencil-n 32.000000', 'frost-n wet-j 32.000000', 'mural-n work-n 32.000000', 'berry-n blossom-n 32.000000', 'decoration-n lighting-n 32.000000', 'man-n muscle-n 32.000000', 'drip-v puddle-n 32.000000', 'porch-n stair-n 32.000000', 'brown-j red-j 32.000000', 'iron-n rusty-j 32.000000', 'apartment-n bedroom-n 32.000000', 'foliage-n lily-n 32.000000', 'face-n happy-j 32.000000', 'airport-n traffic-n 32.000000', 'rain-n wind-n 32.000000', 'handwriting-n sketch-n 32.000000', 'city-n live-v 32.000000', 'rain-n sunny-j 32.000000', 'blonde-j haircut-n 32.000000', 'abandon-v ruin-n 32.000000', 'black-j yellow-j 32.000000', 'bacon-n cooking-n 32.000000', 'dragonfly-n pond-n 32.000000', 'ceiling-n staircase-n 32.000000', 'morning-n time-n 32.000000', 'potato-n sweet-j 32.000000', 'day-n sunny-j 32.000000', 'hotel-n house-n 32.000000', 'guy-n haircut-n 32.000000', 'mud-n sand-n 32.000000', 'staircase-n wall-n 32.000000', 'brown-j white-j 32.000000', 'dinner-n sit-v 32.000000', 'evening-n morning-n 32.000000', 'bench-n sit-v 32.000000', 'hummingbird-n pelican-n 32.000000', 'bike-n chopper-n 32.000000', 'foliage-n tulip-n 32.000000', 'bar-n cafe-n 32.000000', 'autumn-n sunshine-n 32.000000', 'potato-n tomato-n 32.000000', 'scenery-n trail-n 32.000000', 'jacket-n skirt-n 32.000000', 'construction-n skyscraper-n 32.000000', 'chicken-n lamb-n 32.000000', 'grey-j orange-j 32.000000', 'bikini-n lake-n 32.000000', 'carrot-n soup-n 32.000000', 'bar-n diner-n 32.000000', 'dessert-n frozen-j 32.000000', 'cooking-n diner-n 32.000000', 'violet-n white-j 32.000000', 'apple-n dessert-n 32.000000', 'cooking-n noodle-n 32.000000', 'bear-v son-n 32.000000', 'insect-n lizard-n 32.000000', 'foliage-n twig-n 32.000000', 'outdoor-j pool-n 32.000000', 'morning-n sunset-n 32.000000', 'escalator-n subway-n 32.000000', 'bacon-n soup-n 32.000000', 'berry-n sweet-j 32.000000', 'grey-j pink-j 32.000000', 'rain-n sunshine-n 32.000000', 'game-n play-v 32.000000', 'cocktail-n dinner-n 32.000000', 'building-n concrete-j 32.000000', 'street-n town-n 32.000000', 'friend-n love-n 32.000000', 'festival-n musician-n 32.000000', 'berry-n twig-n 32.000000', 'ball-n drop-v 31.000000', 'black-j violet-n 31.000000', 'hawk-n wild-j 31.000000', 'cooking-n salad-n 31.000000', 'floor-n staircase-n 31.000000', 'lawn-n patio-n 31.000000', 'guy-n sport-n 31.000000', 'blossom-n purple-j 31.000000', 'cold-j rain-n 31.000000', 'reptile-n wild-j 31.000000', 'glitter-v sunshine-n 31.000000', 'room-n staircase-n 31.000000', 'mammal-n wild-j 31.000000', 'interior-n paint-v 31.000000', 'forest-n frog-n 31.000000', 'ceiling-n window-n 31.000000', 'coast-n sailing-n 31.000000', 'relax-v sit-v 31.000000', 'fungus-n moss-n 31.000000', 'interior-n staircase-n 31.000000', 'bride-n photographer-n 31.000000', 'dirt-n racing-n 31.000000', 'frozen-j raspberry-n 31.000000', 'boy-n school-n 31.000000', 'brown-j violet-n 31.000000', 'play-v stadium-n 31.000000', 'chapel-n graveyard-n 31.000000', 'dew-n frost-n 31.000000', 'dark-j grey-j 31.000000', 'desert-n mountain-n 31.000000', 'berry-n purple-j 31.000000', 'collage-n illustration-n 31.000000', 'cold-j wet-j 31.000000', 'burger-n cooking-n 31.000000', 'day-n evening-n 31.000000', 'jean-n shirt-n 31.000000', 'blue-j white-j 31.000000', 'giraffe-n lion-n 31.000000', 'dandelion-n foliage-n 31.000000', 'bird-n reptile-n 31.000000', 'bathroom-n floor-n 31.000000', 'love-n smile-n 31.000000', 'small-j village-n 31.000000', 'hat-n jean-n 31.000000', 'bright-j orange-j 31.000000', 'bud-n fruit-n 31.000000', 'fall-v tear-n 31.000000', 'food-n fruit-n 31.000000', 'red-j white-j 31.000000', 'collage-n exhibition-n 31.000000', 'orange-j raspberry-n 31.000000', 'hat-n outfit-n 31.000000', 'hockey-n play-v 31.000000', 'berry-n eat-v 31.000000', 'bag-n pillow-n 31.000000', 'bread-n salad-n 31.000000', 'bathroom-n ceiling-n 31.000000', 'bacon-n burger-n 31.000000', 'ceramic-j floor-n 31.000000', 'fun-n relax-v 31.000000', 'dawn-n misty-j 31.000000', 'hot-j weather-n 31.000000', 'pepper-n potato-n 31.000000', 'pink-j red-j 31.000000', 'interior-n roof-n 31.000000', 'cute-j kid-n 31.000000', 'vine-n wine-n 31.000000', 'skyline-n tower-n 31.000000', 'pet-n terrier-n 31.000000', 'girl-n sexy-j 31.000000', 'downtown-j subway-n 31.000000', 'jump-n leg-n 31.000000', 'dessert-n salad-n 31.000000', 'shirt-n sock-n 31.000000', 'exhibition-n painting-n 31.000000', 'boardwalk-n trail-n 31.000000', 'apple-n blossom-n 31.000000', 'hawk-n mallard-n 31.000000', 'hand-n stand-v 31.000000', 'flower-n yellow-j 31.000000', 'floor-n porch-n 31.000000', 'drip-v wash-v 31.000000', 'foliage-n ivy-n 31.000000', 'cliff-n waterfall-n 30.000000', 'foliage-n fruit-n 30.000000', 'orange-j white-j 30.000000', 'station-n underground-j 30.000000', 'foliage-n yellow-j 30.000000', 'dude-n friend-n 30.000000', 'forest-n tropical-j 30.000000', 'rain-n sun-n 30.000000', 'belly-n dance-n 30.000000', 'man-n sexy-j 30.000000', 'colorful-j outfit-n 30.000000', 'reptile-n rodent-n 30.000000', 'burger-n salad-n 30.000000', 'fruit-n sweet-j 30.000000', 'flamingo-n mallard-n 30.000000', 'garage-n kitchen-n 30.000000', 'roof-n stair-n 30.000000', 'club-n hockey-n 30.000000', 'house-n staircase-n 30.000000', 'feel-v kiss-n 30.000000', 'bright-j red-j 30.000000', 'lake-n valley-n 30.000000', 'door-n patio-n 30.000000', 'apartment-n kitchen-n 30.000000', 'grey-j yellow-j 30.000000', 'chicken-n salad-n 30.000000', 'punk-n rock-n 30.000000', 'bloom-n twig-n 30.000000', 'blonde-j wig-n 30.000000', 'cold-j water-n 30.000000', 'blur-v lens-n 30.000000', 'door-n porch-n 30.000000', 'foliage-n orchid-n 30.000000', 'door-n interior-n 30.000000', 'female-j makeup-n 30.000000', 'cloud-n sunlight-n 30.000000', 'beach-n pebble-n 30.000000', 'bright-j yellow-j 30.000000', 'bed-n floor-n 30.000000', 'cherry-n dessert-n 30.000000', 'misty-j sunrise-n 30.000000', 'dark-j shade-n 30.000000', 'railroad-n underground-j 30.000000', 'cafe-n donut-n 30.000000', 'musician-n punk-n 30.000000', 'memorial-n people-n 30.000000', 'stop-v time-n 30.000000', 'glitter-v star-n 30.000000', 'fun-n idea-n 30.000000', 'band-n uniform-j 30.000000', 'insect-n plant-n 30.000000', 'bedroom-n kitchen-n 30.000000', 'harbour-n scenery-n 30.000000', 'collage-n painting-n 30.000000', 'mist-n sky-n 30.000000', 'dawn-n sunshine-n 30.000000', 'costume-n shirt-n 30.000000', 'mud-n water-n 30.000000', 'blossom-n violet-n 30.000000', 'fishing-n shore-n 30.000000', 'cloud-n sunny-j 30.000000', 'shade-n sunlight-n 30.000000', 'friend-n smile-n 30.000000', 'bacon-n salad-n 30.000000', 'pod-n round-n 30.000000', 'flower-n fruit-n 30.000000', 'abstract-j museum-n 30.000000', 'door-n stair-n 30.000000', 'foot-n tall-j 30.000000', 'cooking-n fruit-n 30.000000', 'burger-n soup-n 30.000000', 'match-n play-v 30.000000', 'cattle-n goat-n 29.000000', 'camera-n theatre-n 29.000000', 'flower-n wild-j 29.000000', 'lick-v lip-n 29.000000', 'lunch-n tea-n 29.000000', 'berry-n dessert-n 29.000000', 'downtown-j shopping-n 29.000000', 'kitchen-n wash-v 29.000000', 'petal-n twig-n 29.000000', 'happy-j kid-n 29.000000', 'amphibian-n bird-n 29.000000', 'cold-j sunny-j 29.000000', 'meat-n soup-n 29.000000', 'camel-n desert-n 29.000000', 'foliage-n shade-n 29.000000', 'restaurant-n room-n 29.000000', 'couple-n family-n 29.000000', 'bird-n mammal-n 29.000000', 'arch-n porch-n 29.000000', 'kitty-n lick-v 29.000000', 'blossom-n ivy-n 29.000000', 'grey-j red-j 29.000000', 'bright-j pink-j 29.000000', 'bay-n cliff-n 29.000000', 'door-n staircase-n 29.000000', 'chess-n toy-n 29.000000', 'gull-n hummingbird-n 29.000000', 'beauty-n peacock-n 29.000000', 'boardwalk-n park-n 29.000000', 'city-n ruin-n 29.000000', 'bay-n swim-v 29.000000', 'daisy-n foliage-n 29.000000', 'apartment-n bathroom-n 29.000000', 'flower-n purple-j 29.000000', 'hill-n path-n 29.000000', 'match-n stadium-n 29.000000', 'monument-n ruin-n 29.000000', 'dark-j white-j 29.000000', 'ancient-j city-n 29.000000', 'lick-v puppy-n 29.000000', 'metal-n punk-n 29.000000', 'hotel-n relax-v 29.000000', 'nut-n sunflower-n 29.000000', 'hot-j wet-j 29.000000', 'glass-n vinyl-n 29.000000', 'foliage-n moss-n 29.000000', 'coast-n scenery-n 29.000000', 'bacon-n bread-n 29.000000', 'brick-n roof-n 29.000000', 'wet-j winter-n 29.000000', 'dark-j silhouette-n 29.000000', 'bacon-n dessert-n 29.000000', 'floor-n stair-n 29.000000', 'day-n lunch-n 29.000000', 'line-n lunch-n 29.000000', 'room-n sit-v 29.000000', 'interior-n outdoor-j 29.000000', 'shirt-n white-j 29.000000', 'lick-v paw-n 29.000000', 'brown-j pink-j 29.000000', 'friend-n fun-n 29.000000', 'city-n downtown-j 29.000000', 'pool-n relax-v 28.000000', 'bird-n dragonfly-n 28.000000', 'bacon-n tomato-n 28.000000', 'dandelion-n seed-n 28.000000', 'purple-j shade-n 28.000000', 'bacon-n pepper-n 28.000000', 'dark-j purple-j 28.000000', 'door-n floor-n 28.000000', 'sidewalk-n street-n 28.000000', 'bacon-n sandwich-n 28.000000', 'petal-n pink-j 28.000000', 'colour-n dark-j 28.000000', 'brick-n staircase-n 28.000000', 'fog-n sunny-j 28.000000', 'valley-n waterfall-n 28.000000', 'rice-n soup-n 28.000000', 'patio-n pool-n 28.000000', 'patio-n sit-v 28.000000', 'river-n scenery-n 28.000000', 'beard-n blonde-j 28.000000', 'nest-n stork-n 28.000000', 'carrot-n pepper-n 28.000000', 'collage-n paint-v 28.000000', 'jump-n swimming-n 28.000000', 'chapel-n gravestone-n 28.000000', 'feel-v smile-n 28.000000', 'flag-n stripe-n 28.000000', 'harbour-n town-n 28.000000', 'guitar-n punk-n 28.000000', 'scenery-n sunny-j 28.000000', 'christmas-n valentine-n 28.000000', 'bloom-n pink-j 28.000000', 'bear-v daughter-n 28.000000', 'insect-n rodent-n 28.000000', 'bedroom-n floor-n 28.000000', 'stair-n wall-n 28.000000', 'chapel-n ruin-n 28.000000', 'beef-n tomato-n 28.000000', 'doodle-n scratch-n 28.000000', 'daffodil-n purple-j 28.000000', 'lake-n scenery-n 28.000000', 'roof-n staircase-n 28.000000', 'boy-n live-v 28.000000', 'chain-n store-n 28.000000', 'coast-n hill-n 28.000000', 'mushroom-n pepper-n 28.000000', 'porch-n window-n 28.000000', 'hot-j water-n 28.000000', 'sock-n white-j 28.000000', 'arch-n bridge-n 28.000000', 'dessert-n raspberry-n 28.000000', 'brick-n ceiling-n 28.000000', 'scenery-n sunshine-n 28.000000', 'city-n square-j 28.000000', 'stand-v walk-v 28.000000', 'evening-n fun-n 28.000000', 'happy-j sexy-j 28.000000', 'burger-n mac-n 28.000000', 'paint-v sculpture-n 28.000000', 'misty-j morning-n 28.000000', 'frost-n rain-n 28.000000', 'color-n shade-n 28.000000', 'bacon-n potato-n 28.000000', 'patio-n stair-n 28.000000', 'hot-j wash-v 27.000000', 'button-n sticker-n 27.000000', 'cute-j happy-j 27.000000', 'happy-j tear-n 27.000000', 'pepper-n soup-n 27.000000', 'alley-n racing-n 27.000000', 'smile-n tear-n 27.000000', 'train-n underground-j 27.000000', 'blonde-j curl-v 27.000000', 'flamingo-n mammal-n 27.000000', 'porch-n staircase-n 27.000000', 'ford-n river-n 27.000000', 'room-n stair-n 27.000000', 'face-n glitter-v 27.000000', 'nest-n reptile-n 27.000000', 'sailing-n sink-v 27.000000', 'floor-n kitchen-n 27.000000', 'cottage-n garden-n 27.000000', 'day-n weather-n 27.000000', 'amphibian-n insect-n 27.000000', 'eat-v sweet-j 27.000000', 'pregnant-j round-n 27.000000', 'brown-j feather-n 27.000000', 'bed-n sit-v 27.000000', 'bike-n rally-n 27.000000', 'apartment-n patio-n 27.000000', 'cooking-n dessert-n 27.000000', 'lily-n purple-j 27.000000', 'kitchen-n patio-n 27.000000', 'line-n subway-n 27.000000', 'breakfast-n room-n 27.000000', 'gull-n reptile-n 27.000000', 'dirty-j rusty-j 27.000000', 'bath-n bedroom-n 27.000000', 'cottage-n patio-n 27.000000', 'misty-j sunshine-n 27.000000', 'band-n metal-n 27.000000', 'skyline-n tall-j 27.000000', 'berry-n foliage-n 27.000000', 'mushroom-n salad-n 27.000000', 'abandon-v soldier-n 27.000000', 'bath-n kitchen-n 27.000000', 'sit-v stop-v 27.000000', 'outdoor-j swimming-n 27.000000', 'ruin-n stone-n 27.000000', 'building-n sidewalk-n 27.000000', 'fall-v stop-v 27.000000', 'cloud-n ripple-n 27.000000', 'cliff-n scenery-n 27.000000', 'salad-n strawberry-n 27.000000', 'graveyard-n ruin-n 27.000000', 'pepper-n tomato-n 27.000000', 'line-n metro-n 27.000000', 'bird-n wild-j 27.000000', 'hill-n road-n 27.000000', 'cliff-n harbour-n 27.000000', 'clothes-n sexy-j 27.000000', 'baseball-n club-n 27.000000', 'petal-n purple-j 27.000000', 'collar-n skirt-n 27.000000', 'cottage-n sleep-v 27.000000', 'match-n round-n 27.000000', 'kitchen-n stair-n 27.000000', 'church-n graveyard-n 27.000000', 'lighthouse-n wall-n 27.000000', 'kitchen-n sit-v 27.000000', 'dawn-n spring-n 27.000000', 'hot-j spring-n 27.000000', 'flower-n weather-n 27.000000', 'child-n fun-n 27.000000', 'evening-n walk-v 27.000000', 'cliff-n sea-n 27.000000', 'cold-j mist-n 27.000000', 'station-n theatre-n 27.000000', 'dusk-n misty-j 27.000000', 'friend-n lady-n 27.000000', 'mountain-n sea-n 26.000000', 'escalator-n metro-n 26.000000', 'live-v old-j 26.000000', 'friend-n guy-n 26.000000', 'theatre-n tv-n 26.000000', 'ceiling-n kitchen-n 26.000000', 'nature-n snowman-n 26.000000', 'coin-n ticket-n 26.000000', 'plane-n sailing-n 26.000000', 'sea-n sink-v 26.000000', 'bench-n boardwalk-n 26.000000', 'happy-j kiss-n 26.000000', 'bath-n bed-n 26.000000', 'restaurant-n shopping-n 26.000000', 'canine-j run-v 26.000000', 'lunch-n sit-v 26.000000', 'bus-n rail-n 26.000000', 'frog-n tropical-j 26.000000', 'bathroom-n bed-n 26.000000', 'goose-n wolf-n 26.000000', 'happy-j mom-n 26.000000', 'black-j paint-v 26.000000', 'glitter-v scenery-n 26.000000', 'beef-n salad-n 26.000000', 'construction-n downtown-j 26.000000', 'parking-n underground-j 26.000000', 'park-n skate-n 26.000000', 'apartment-n pool-n 26.000000', 'flood-n line-n 26.000000', 'marble-n wall-n 26.000000', 'hummingbird-n tropical-j 26.000000', 'palace-n ruin-n 26.000000', 'panda-n pig-n 26.000000', 'frost-n shade-n 26.000000', 'cherry-n sweet-j 26.000000', 'carrot-n fruit-n 26.000000', 'brick-n skyscraper-n 26.000000', 'collage-n sculpture-n 26.000000', 'fruit-n potato-n 26.000000', 'grey-j stripe-n 26.000000', 'patio-n room-n 26.000000', 'fun-n sexy-j 26.000000', 'blue-j fabric-n 26.000000', 'guy-n sexy-j 26.000000', 'guitar-n track-n 26.000000', 'misty-j scenery-n 26.000000', 'kitchen-n porch-n 26.000000', 'sweet-j wine-n 26.000000', 'cute-j guy-n 26.000000', 'bedroom-n relax-v 26.000000', 'hummingbird-n insect-n 26.000000', 'hill-n horizon-n 26.000000', 'beef-n pepper-n 26.000000', 'hand-n leave-v 26.000000', 'beef-n deer-n 26.000000', 'frog-n whale-n 26.000000', 'bright-j shade-n 26.000000', 'cooking-n frozen-j 26.000000', 'festival-n gate-n 26.000000', 'interior-n object-n 25.000000', 'bathroom-n sit-v 25.000000', 'smoke-n sun-n 25.000000', 'crochet-n jewelry-n 25.000000', 'architecture-n skyline-n 25.000000', 'cold-j puddle-n 25.000000', 'blur-v eye-n 25.000000', 'guy-n sleep-v 25.000000', 'baseball-n shirt-n 25.000000', 'amphibian-n pelican-n 25.000000', 'shade-n violet-n 25.000000', 'green-j shade-n 25.000000', 'evening-n sunny-j 25.000000', 'blue-j stripe-n 25.000000', 'patio-n staircase-n 25.000000', 'puddle-n street-n 25.000000', 'eye-n smile-n 25.000000', 'canine-j lick-v 25.000000', 'outfit-n punk-n 25.000000', 'dragonfly-n reptile-n 25.000000', 'mist-n sunshine-n 25.000000', 'castle-n ruin-n 25.000000', 'angel-n sculpture-n 25.000000', 'bud-n ivy-n 25.000000', 'chicken-n mammal-n 25.000000', 'family-n live-v 25.000000', 'carrot-n sunflower-n 25.000000', 'interior-n stair-n 25.000000', 'craft-n game-n 25.000000', 'valley-n village-n 25.000000', 'brown-j gull-n 25.000000', 'decoration-n tulip-n 25.000000', 'bud-n pink-j 25.000000', 'dessert-n orange-j 25.000000', 'mammal-n reptile-n 25.000000', 'cute-j sexy-j 25.000000', 'relax-v scenery-n 25.000000', 'blue-j bright-j 25.000000', 'cold-j misty-j 25.000000', 'floor-n skyscraper-n 25.000000', 'coast-n valley-n 25.000000', 'ceiling-n stair-n 25.000000', 'couple-n live-v 25.000000', 'red-j stripe-n 25.000000', 'sing-v write-v 25.000000', 'hang-v stand-v 25.000000', 'meat-n pepper-n 25.000000', 'insect-n mammal-n 25.000000', 'track-n vinyl-n 25.000000', 'show-n sketch-n 25.000000', 'clothes-n cute-j 25.000000', 'harbour-n sink-v 25.000000', 'dude-n sexy-j 25.000000', 'blue-j shade-n 25.000000', 'garden-n house-n 25.000000', 'crane-n wild-j 25.000000', 'feel-v tear-n 24.000000', 'bar-n relax-v 24.000000', 'breakfast-n sleep-v 24.000000', 'shore-n valley-n 24.000000', 'amphibian-n wild-j 24.000000', 'door-n kitchen-n 24.000000', 'sexy-j smile-n 24.000000', 'stripe-n white-j 24.000000', 'family-n male-n 24.000000', 'hummingbird-n mammal-n 24.000000', 'amphibian-n dragonfly-n 24.000000', 'rice-n yellow-j 24.000000', 'happy-j time-n 24.000000', 'line-n street-n 24.000000', 'black-j skirt-n 24.000000', 'porch-n wall-n 24.000000', 'drop-v hang-v 24.000000', 'mist-n sunny-j 24.000000', 'pepper-n strawberry-n 24.000000', 'ruin-n skyline-n 24.000000', 'nude-j painting-n 24.000000', 'diner-n patio-n 24.000000', 'bridge-n ford-n 24.000000', 'blonde-j cute-j 24.000000', 'morning-n weather-n 24.000000', 'dress-n match-n 24.000000', 'fungus-n rust-n 24.000000', 'stripe-n yellow-j 24.000000', 'chapel-n tower-n 24.000000', 'feather-n wild-j 24.000000', 'cake-n christmas-n 24.000000', 'bright-j raspberry-n 24.000000', 'harbor-n sink-v 24.000000', 'barn-n owl-n 24.000000', 'daisy-n purple-j 24.000000', 'frost-n grass-n 24.000000', 'blue-j shirt-n 24.000000', 'post-v view-n 24.000000', 'hawk-n mammal-n 24.000000', 'garden-n kitchen-n 24.000000', 'bright-j purple-j 24.000000', 'cute-j haircut-n 24.000000', 'hawk-n reptile-n 24.000000', 'fun-n lego-n 24.000000', 'snow-n sunshine-n 24.000000', 'bloom-n purple-j 24.000000', 'family-n female-j 24.000000', 'orange-j salad-n 24.000000', 'architecture-n shade-n 24.000000', 'bedroom-n stair-n 24.000000', 'hill-n town-n 24.000000', 'bread-n dessert-n 24.000000', 'cathedral-n step-n 24.000000', 'bedroom-n staircase-n 24.000000', 'shore-n town-n 24.000000', 'bench-n game-n 24.000000', 'mist-n sunlight-n 24.000000', 'fountain-n marble-n 24.000000', 'makeup-n reflection-n 24.000000', 'cocktail-n relax-v 24.000000', 'sketch-n texture-n 24.000000', 'deer-n elephant-n 24.000000', 'bed-n ceiling-n 24.000000', 'evening-n relax-v 24.000000', 'berry-n ivy-n 24.000000', 'ruin-n village-n 24.000000', 'cafe-n street-n 24.000000', 'palm-n twig-n 24.000000', 'frost-n spring-n 24.000000', 'daisy-n pink-j 24.000000', 'dirty-j hand-n 24.000000', 'arch-n wall-n 24.000000', 'porch-n room-n 24.000000', 'cottage-n scenery-n 24.000000', 'fruit-n meat-n 24.000000', 'cute-j smile-n 24.000000', 'bath-n floor-n 24.000000', 'old-j town-n 24.000000', 'skirt-n white-j 24.000000', 'glitter-v misty-j 23.000000', 'fire-n sand-n 23.000000', 'sit-v staircase-n 23.000000', 'blue-j dark-j 23.000000', 'nail-n rusty-j 23.000000', 'ceiling-n marble-n 23.000000', 'basket-n dinner-n 23.000000', 'card-n party-n 23.000000', 'bright-j foliage-n 23.000000', 'cold-j drip-v 23.000000', 'lamb-n snow-n 23.000000', 'cafe-n relax-v 23.000000', 'cathedral-n ruin-n 23.000000', 'hill-n river-n 23.000000', 'friend-n night-n 23.000000', 'orange-j shade-n 23.000000', 'live-v male-n 23.000000', 'coffee-n lunch-n 23.000000', 'key-j palace-n 23.000000', 'shop-n show-n 23.000000', 'burger-n dessert-n 23.000000', 'morning-n relax-v 23.000000', 'craft-n note-n 23.000000', 'dessert-n sandwich-n 23.000000', 'dirty-j feel-v 23.000000', 'beer-n patio-n 23.000000', 'eat-v frozen-j 23.000000', 'brick-n porch-n 23.000000', 'ceiling-n door-n 23.000000', 'deer-n insect-n 23.000000', 'happy-j home-n 23.000000', 'rock-n track-n 23.000000', 'footprint-n tile-n 23.000000', 'exhibition-n work-n 23.000000', 'city-n lamp-n 23.000000', 'cute-j lady-n 23.000000', 'shade-n white-j 23.000000', 'beauty-n orchid-n 23.000000', 'hummingbird-n rodent-n 23.000000', 'haircut-n sexy-j 23.000000', 'arch-n concrete-j 23.000000', 'airport-n asphalt-n 23.000000', 'air-n dew-n 23.000000', 'pregnancy-n sit-v 23.000000', 'frost-n plant-n 23.000000', 'forest-n hummingbird-n 23.000000', 'kiss-n smile-n 23.000000', 'eat-v rabbit-n 23.000000', 'autumn-n shade-n 23.000000', 'guy-n kid-n 23.000000', 'fall-v love-n 23.000000', 'oak-n rose-n 23.000000', 'city-n firework-n 23.000000', 'lamb-n mother-n 23.000000', 'cone-n diamond-n 23.000000', 'concrete-j school-n 23.000000', 'scenery-n sketch-n 23.000000', 'face-n guy-n 23.000000', 'scenery-n shore-n 23.000000', 'daisy-n gravestone-n 23.000000', 'field-n skyscraper-n 23.000000', 'leather-n rope-n 23.000000', 'sink-v sunset-n 23.000000', 'amphibian-n brown-j 23.000000', 'evening-n misty-j 23.000000', 'miniature-j painting-n 23.000000', 'dessert-n wine-n 23.000000', 'foliage-n tall-j 23.000000', 'evening-n lunch-n 23.000000', 'dark-j orange-j 23.000000', 'dessert-n lunch-n 23.000000', 'misty-j mountain-n 23.000000', 'boy-n hand-n 23.000000', 'dessert-n soup-n 23.000000', 'blue-j skirt-n 22.000000', 'dark-j pink-j 22.000000', 'interior-n patio-n 22.000000', 'sunny-j wet-j 22.000000', 'camera-n painting-n 22.000000', 'automobile-n police-n 22.000000', 'boardwalk-n evening-n 22.000000', 'guy-n smile-n 22.000000', 'sit-v time-n 22.000000', 'pink-j skirt-n 22.000000', 'ivy-n wall-n 22.000000', 'rock-n sing-v 22.000000', 'action-n truck-n 22.000000', 'hill-n shore-n 22.000000', 'happy-j morning-n 22.000000', 'demolition-n skyscraper-n 22.000000', 'happy-j idea-n 22.000000', 'hummingbird-n reptile-n 22.000000', 'breakfast-n sit-v 22.000000', 'light-n sleep-v 22.000000', 'cute-j feel-v 22.000000', 'bead-n gold-n 22.000000', 'clothes-n haircut-n 22.000000', 'evening-n sunshine-n 22.000000', 'foliage-n violet-n 22.000000', 'cathedral-n interior-n 22.000000', 'post-v quote-n 22.000000', 'mammal-n pelican-n 22.000000', 'escalator-n underground-j 22.000000', 'band-n outfit-n 22.000000', 'church-n interior-n 22.000000', 'market-n sushi-n 22.000000', 'grey-j rusty-j 22.000000', 'arch-n brick-n 22.000000', 'feel-v sleep-v 22.000000', 'insect-n twig-n 22.000000', 'colorful-j toy-n 22.000000', 'cherry-n vine-n 22.000000', 'dessert-n noodle-n 22.000000', 'black-j pencil-n 22.000000', 'band-n track-n 22.000000', 'happy-j sleep-v 22.000000', 'skate-n vehicle-n 22.000000', 'dessert-n rice-n 22.000000', 'movie-n shopping-n 22.000000', 'shade-n twig-n 22.000000', 'frost-n sunny-j 22.000000', 'misty-j sky-n 22.000000', 'misty-j sunset-n 22.000000', 'black-j stripe-n 22.000000', 'church-n porch-n 22.000000', 'morning-n smile-n 22.000000', 'autumn-n frost-n 22.000000', 'bath-n patio-n 22.000000', 'person-n stair-n 22.000000', 'pumpkin-n valley-n 22.000000', 'dark-j pod-n 22.000000', 'child-n live-v 22.000000', 'orchid-n patio-n 22.000000', 'shade-n yellow-j 21.000000', 'dirty-j drip-v 21.000000', 'key-j stone-n 21.000000', 'people-n stair-n 21.000000', 'bathroom-n staircase-n 21.000000', 'dome-n interior-n 21.000000', 'breakfast-n hotel-n 21.000000', 'bike-n patio-n 21.000000', 'female-j old-j 21.000000', 'glitter-v smile-n 21.000000', 'downtown-j shore-n 21.000000', 'fruit-n sunflower-n 21.000000', 'feline-j reptile-n 21.000000', 'run-v train-n 21.000000', 'shopping-n street-n 21.000000', 'cat-n garden-n 21.000000', 'cute-j mom-n 21.000000', 'steel-n wing-n 21.000000', 'guy-n walk-v 21.000000', 'horse-n work-n 21.000000', 'chipmunk-n wolf-n 21.000000', 'red-j shade-n 21.000000', 'school-n traffic-n 21.000000', 'dance-n hotel-n 21.000000', 'sunny-j winter-n 21.000000', 'ceramic-j colour-n 21.000000', 'house-n poster-n 21.000000', 'colorful-j frame-n 21.000000', 'sweet-j vine-n 21.000000', 'barn-n food-n 21.000000', 'field-n squirrel-n 21.000000', 'brown-j hawk-n 21.000000', 'city-n small-j 21.000000', 'dark-j violet-n 21.000000', 'brick-n interior-n 21.000000', 'couple-n female-j 21.000000', 'cliff-n sand-n 21.000000', 'key-j motor-n 21.000000', 'square-j town-n 21.000000', 'misty-j sunny-j 21.000000', 'jean-n wash-v 21.000000', 'foot-n piano-n 21.000000', 'model-n toe-n 21.000000', 'crystal-n spiral-n 21.000000', 'cliff-n shore-n 21.000000', 'lake-n whale-n 21.000000', 'shore-n waterfall-n 21.000000', 'foliage-n pink-j 21.000000', 'hawk-n insect-n 21.000000', 'curl-v whisker-n 21.000000', 'dessert-n pepper-n 21.000000', 'dinner-n room-n 21.000000', 'art-n drive-n 21.000000', 'drop-v time-n 21.000000', 'hang-v sit-v 21.000000', 'skin-n sunglasses-n 21.000000', 'lunch-n morning-n 21.000000', 'drug-n musician-n 21.000000', 'redhead-n rusty-j 21.000000', 'live-v race-n 21.000000', 'fall-v stand-v 21.000000', 'cliff-n fence-n 21.000000', 'misty-j snow-n 21.000000', 'gasoline-n town-n 21.000000', 'decoration-n twig-n 21.000000', 'flower-n shade-n 21.000000', 'skin-n skirt-n 21.000000', 'feel-v idea-n 21.000000', 'ruin-n town-n 21.000000', 'bedroom-n breakfast-n 21.000000', 'lunch-n relax-v 21.000000', 'fountain-n hill-n 20.000000', 'couple-n male-n 20.000000', 'bathroom-n patio-n 20.000000', 'dusk-n hummingbird-n 20.000000', 'guitar-n vinyl-n 20.000000', 'bright-j fruit-n 20.000000', 'dead-j hang-v 20.000000', 'heart-n wing-n 20.000000', 'salad-n sunflower-n 20.000000', 'bedroom-n patio-n 20.000000', 'badge-n metro-n 20.000000', 'fun-n time-n 20.000000', 'dark-j red-j 20.000000', 'concrete-j interior-n 20.000000', 'cone-n windmill-n 20.000000', 'racing-n shirt-n 20.000000', 'mom-n smile-n 20.000000', 'object-n scooter-n 20.000000', 'cone-n hill-n 20.000000', 'breakfast-n relax-v 20.000000', 'friend-n relax-v 20.000000', 'fun-n guy-n 20.000000', 'black-j bright-j 20.000000', 'dancer-n palace-n 20.000000', 'frozen-j salad-n 20.000000', 'brown-j hummingbird-n 20.000000', 'escalator-n railway-n 20.000000', 'camel-n outdoor-j 20.000000', 'autumn-n bud-n 20.000000', 'male-n old-j 20.000000', 'hold-v nest-n 20.000000', 'cute-j mammal-n 20.000000', 'baseball-n show-n 20.000000', 'patio-n spring-n 20.000000', 'mammal-n nest-n 20.000000', 'cow-n pregnancy-n 20.000000', 'fun-n night-n 20.000000', 'game-n rocket-n 20.000000', 'downtown-j ruin-n 20.000000', 'makeup-n people-n 20.000000', 'interior-n porch-n 20.000000', 'bed-n patio-n 20.000000', 'relax-v sunshine-n 20.000000', 'dark-j yellow-j 20.000000', 'floor-n sit-v 20.000000', 'grave-n number-n 20.000000', 'mill-n sunflower-n 20.000000', 'farm-n wind-n 20.000000', 'cold-j wash-v 20.000000', 'drip-v hot-j 20.000000', 'idea-n people-n 20.000000', 'couple-n old-j 20.000000', 'food-n gull-n 20.000000', 'gate-n hotel-n 20.000000', 'glitter-v night-n 20.000000', 'cold-j sun-n 20.000000', 'chicken-n pepper-n 20.000000', 'salad-n sweet-j 20.000000', 'porch-n stone-n 20.000000', 'coffee-n room-n 20.000000', 'berry-n bright-j 20.000000', 'amphibian-n hummingbird-n 20.000000', 'flamingo-n insect-n 20.000000', 'club-n shirt-n 20.000000', 'porch-n tower-n 20.000000', 'skateboard-n swimsuit-n 20.000000', 'desert-n road-n 20.000000', 'kiss-n tear-n 20.000000', 'feather-n grey-j 20.000000', 'club-n match-n 19.000000', 'sit-v sleep-v 19.000000', 'chapel-n porch-n 19.000000', 'figure-n spiral-n 19.000000', 'bud-n purple-j 19.000000', 'bird-n shade-n 19.000000', 'blonde-j dark-j 19.000000', 'burger-n frozen-j 19.000000', 'chain-n engine-n 19.000000', 'bathroom-n porch-n 19.000000', 'country-n work-n 19.000000', 'leave-v stop-v 19.000000', 'desk-n white-j 19.000000', 'object-n piano-n 19.000000', 'can-n mill-n 19.000000', 'female-j race-n 19.000000', 'frost-n sunshine-n 19.000000', 'soup-n sweet-j 19.000000', 'black-j seat-n 19.000000', 'lion-n pelican-n 19.000000', 'graffito-n interior-n 19.000000', 'apartment-n sleep-v 19.000000', 'cold-j summer-n 19.000000', 'market-n orange-j 19.000000', 'guy-n kiss-n 19.000000', 'dirty-j guy-n 19.000000', 'arm-n caterpillar-n 19.000000', 'foliage-n frost-n 19.000000', 'gravestone-n pattern-n 19.000000', 'shop-n summer-n 19.000000', 'petal-n shade-n 19.000000', 'gull-n mammal-n 19.000000', 'cone-n palm-n 19.000000', 'makeup-n town-n 19.000000', 'gull-n insect-n 19.000000', 'dessert-n meat-n 19.000000', 'morning-n sit-v 19.000000', 'doll-n new-j 19.000000', 'butterfly-n glitter-v 19.000000', 'interior-n skyscraper-n 19.000000', 'market-n white-j 19.000000', 'cute-j fun-n 19.000000', 'night-n sunny-j 19.000000', 'bed-n staircase-n 19.000000', 'miniature-j paint-v 19.000000', 'bloom-n glitter-v 19.000000', 'evening-n friend-n 19.000000', 'city-n mill-n 19.000000', 'coast-n downtown-j 18.000000', 'dew-n sunshine-n 18.000000', 'dragonfly-n underwater-j 18.000000', 'star-n storm-n 18.000000', 'patio-n wash-v 18.000000', 'cold-j ear-n 18.000000', 'house-n windmill-n 18.000000', 'fly-v toy-n 18.000000', 'breakfast-n evening-n 18.000000', 'hang-v rusty-j 18.000000', 'dinner-n relax-v 18.000000', 'aircraft-n door-n 18.000000', 'porch-n ruin-n 18.000000', 'cop-n dirty-j 18.000000', 'cross-n tower-n 18.000000', 'city-n old-j 18.000000', 'cold-j sunshine-n 18.000000', 'dragon-n metal-n 18.000000', 'light-n shed-v 18.000000', 'hotel-n library-n 18.000000', 'feel-v friend-n 18.000000', 'parking-n scenery-n 18.000000', 'ruin-n tower-n 18.000000', 'abandon-v railroad-n 18.000000', 'bright-j violet-n 18.000000', 'couple-n makeup-n 18.000000', 'dude-n smile-n 18.000000', 'dirty-j rabbit-n 18.000000', 'smile-n walk-v 18.000000', 'autumn-n daffodil-n 18.000000', 'hotel-n sand-n 18.000000', 'crystal-n dirt-n 18.000000', 'reptile-n stork-n 18.000000', 'coast-n sink-v 18.000000', 'dark-j rusty-j 18.000000', 'band-n vinyl-n 18.000000', 'parrot-n reptile-n 18.000000', 'steel-n town-n 18.000000', 'architecture-n table-n 18.000000', 'bedroom-n porch-n 18.000000', 'aquarium-n seagull-n 18.000000', 'butterfly-n transformer-n 18.000000', 'feel-v sit-v 18.000000', 'landscape-n stadium-n 18.000000', 'lunch-n walk-v 18.000000', 'church-n cookie-n 18.000000', 'stripe-n violet-n 18.000000', 'origami-n white-j 18.000000', 'bag-n flag-n 18.000000', 'escalator-n station-n 18.000000', 'dawn-n snow-n 18.000000', 'green-j lantern-n 18.000000', 'painting-n work-n 18.000000', 'pigeon-n round-n 18.000000', 'haircut-n smile-n 18.000000', 'coast-n sketch-n 18.000000', 'colorful-j duck-n 18.000000', 'man-n stand-v 18.000000', 'demolition-n interior-n 18.000000', 'pelican-n toe-n 18.000000', 'garage-n garden-n 18.000000', 'brown-j insect-n 18.000000', 'family-n old-j 18.000000', 'brown-j pelican-n 18.000000', 'fountain-n parade-n 18.000000', 'fungus-n insect-n 18.000000', 'female-j live-v 18.000000', 'frost-n hot-j 18.000000', 'handle-v shop-n 17.000000', 'happy-j stand-v 17.000000', 'collection-n work-n 17.000000', 'pepper-n sunflower-n 17.000000', 'graphic-j roof-n 17.000000', 'play-v spiral-n 17.000000', 'cute-j fashion-n 17.000000', 'ball-n square-j 17.000000', 'red-j tea-n 17.000000', 'port-n sweet-j 17.000000', 'lunch-n sunny-j 17.000000', 'night-n stop-v 17.000000', 'muscle-n nature-n 17.000000', 'guy-n sit-v 17.000000', 'game-n scooter-n 17.000000', 'interior-n toy-n 17.000000', 'gate-n pebble-n 17.000000', 'blue-j sock-n 17.000000', 'bedroom-n pool-n 17.000000', 'graveyard-n house-n 17.000000', 'foot-n friend-n 17.000000', 'cute-j idea-n 17.000000', 'bed-n picture-n 17.000000', 'glass-n road-n 17.000000', 'bed-n kitchen-n 17.000000', 'dusk-n gull-n 17.000000', 'bicycle-n green-j 17.000000', 'shade-n whale-n 17.000000', 'lab-n spider-n 17.000000', 'bar-n stair-n 17.000000', 'hang-v time-n 17.000000', 'reptile-n swim-v 17.000000', 'happy-j night-n 17.000000', 'dude-n fun-n 17.000000', 'branch-n tea-n 17.000000', 'club-n play-v 17.000000', 'garbage-n lunch-n 17.000000', 'interior-n tower-n 17.000000', 'breakfast-n people-n 17.000000', 'couple-n race-n 17.000000', 'bay-n porch-n 17.000000', 'country-n library-n 17.000000', 'black-j cigarette-n 17.000000', 'handle-v tram-n 17.000000', 'feel-v stair-n 17.000000', 'oak-n petal-n 17.000000', 'lake-n town-n 17.000000', 'play-v sign-v 17.000000', 'old-j race-n 17.000000', 'parade-n store-n 17.000000', 'jellyfish-n texture-n 17.000000', 'curl-v leaf-n 17.000000', 'hummingbird-n moss-n 17.000000', 'book-n gold-n 17.000000', 'desk-n match-n 17.000000', 'handle-v lighting-n 17.000000', 'frozen-j soup-n 17.000000', 'dude-n sit-v 17.000000', 'amphibian-n stork-n 16.000000', 'asphalt-n crane-n 16.000000', 'bright-j grey-j 16.000000', 'flight-n jaguar-n 16.000000', 'happy-j toe-n 16.000000', 'bathroom-n stair-n 16.000000', 'bay-n curve-n 16.000000', 'foot-n train-n 16.000000', 'snow-n sunny-j 16.000000', 'blue-j happy-j 16.000000', 'sunshine-n wet-j 16.000000', 'clown-n jellyfish-n 16.000000', 'family-n town-n 16.000000', 'pattern-n time-n 16.000000', 'cherry-n peel-n 16.000000', 'bakery-n vehicle-n 16.000000', 'cross-n post-v 16.000000', 'garbage-n underground-j 16.000000', 'bible-n leaf-n 16.000000', 'nature-n new-j 16.000000', 'cute-j dude-n 16.000000', 'curve-n dance-n 16.000000', 'autumn-n hat-n 16.000000', 'fabric-n handle-v 16.000000', 'arm-n white-j 16.000000', 'feel-v fun-n 16.000000', 'bridge-n ceramic-j 16.000000', 'ruin-n valley-n 16.000000', 'castle-n patio-n 16.000000', 'button-n grey-j 16.000000', 'club-n sign-v 16.000000', 'feather-n insect-n 16.000000', 'hotel-n oak-n 16.000000', 'alley-n punk-n 16.000000', 'design-n muscle-n 16.000000', 'circle-n snake-n 16.000000', 'auto-n quote-n 16.000000', 'post-v white-j 16.000000', 'animal-n clown-n 16.000000', 'dinner-n sleep-v 16.000000', 'office-n woman-n 16.000000', 'line-n underground-j 16.000000', 'metro-n television-n 16.000000', 'waterfall-n wood-n 16.000000', 'relax-v restaurant-n 16.000000', 'bed-n stair-n 16.000000', 'dude-n husky-n 16.000000', 'demolition-n skyline-n 16.000000', 'ceiling-n patio-n 16.000000', 'flight-n museum-n 16.000000', 'paper-n tattoo-n 16.000000', 'action-n subway-n 16.000000', 'grave-n shore-n 16.000000', 'sunshine-n winter-n 16.000000', 'ford-n wall-n 16.000000', 'band-n stocking-n 16.000000', 'dirty-j tear-n 16.000000', 'leg-n stripe-n 16.000000', 'family-n square-j 16.000000', 'eye-n sky-n 16.000000', 'dinner-n morning-n 16.000000', 'apartment-n beach-n 16.000000', 'bus-n crane-n 16.000000', 'aquarium-n coin-n 16.000000', 'path-n sunflower-n 16.000000', 'red-j uniform-j 16.000000', 'band-n ear-n 16.000000', 'kitchen-n staircase-n 16.000000', 'glitter-v vintage-j 16.000000', 'gold-n texture-n 16.000000', 'air-n carnival-n 16.000000', 'guy-n stand-v 16.000000', 'bacon-n sweet-j 16.000000', 'abstract-j feel-v 16.000000', 'band-n bride-n 16.000000', 'mom-n sit-v 15.000000', 'foliage-n purple-j 15.000000', 'husky-n painting-n 15.000000', 'evening-n surfer-n 15.000000', 'postcard-n texture-n 15.000000', 'breakfast-n night-n 15.000000', 'makeup-n skull-n 15.000000', 'guy-n tear-n 15.000000', 'hamster-n lock-v 15.000000', 'chess-n family-n 15.000000', 'fun-n haircut-n 15.000000', 'bud-n shade-n 15.000000', 'ad-n track-n 15.000000', 'dead-j pigeon-n 15.000000', 'chipmunk-n illustration-n 15.000000', 'cold-j silver-n 15.000000', 'insect-n number-n 15.000000', 'bar-n boat-n 15.000000', 'restaurant-n scenery-n 15.000000', 'hair-n stencil-n 15.000000', 'guy-n idea-n 15.000000', 'gravestone-n silhouette-n 15.000000', 'bright-j mist-n 15.000000', 'coin-n musician-n 15.000000', 'arm-n bicycle-n 15.000000', 'hang-v morning-n 15.000000', 'demolition-n tall-j 15.000000', 'bedroom-n diner-n 15.000000', 'candle-n line-n 15.000000', 'bar-n ship-n 15.000000', 'club-n cone-n 15.000000', 'art-n christmas-n 15.000000', 'travel-n wood-n 15.000000', 'foot-n outdoor-j 15.000000', 'hang-v leave-v 15.000000', 'rusty-j shade-n 15.000000', 'abstract-j moon-n 15.000000', 'auto-n round-n 15.000000', 'mist-n temple-n 15.000000', 'stripe-n urban-j 15.000000', 'smile-n view-n 15.000000', 'ripple-n shadow-n 15.000000', 'dirty-j fun-n 15.000000', 'haircut-n hang-v 15.000000', 'brick-n skyline-n 15.000000', 'bathroom-n sleep-v 15.000000', 'school-n tear-n 15.000000', 'cute-j friend-n 15.000000', 'action-n dress-n 15.000000', 'cow-n station-n 15.000000', 'play-v sailing-n 15.000000', 'fungus-n pattern-n 15.000000', 'button-n police-n 15.000000', 'ceramic-j church-n 15.000000', 'home-n smoking-n 15.000000', 'food-n wild-j 15.000000', 'colorful-j wood-n 15.000000', 'smile-n time-n 15.000000', 'amphibian-n flamingo-n 15.000000', 'apartment-n child-n 15.000000', 'graveyard-n silver-n 15.000000', 'outfit-n sign-v 15.000000', 'dude-n kid-n 15.000000', 'pole-n weather-n 15.000000', 'city-n round-n 15.000000', 'nail-n wolf-n 15.000000', 'night-n sunshine-n 15.000000', 'bath-n sleep-v 15.000000', 'hang-v stencil-n 15.000000', 'cherry-n meat-n 14.000000', 'blue-j poster-n 14.000000', 'fire-n movie-n 14.000000', 'draw-v wing-n 14.000000', 'husky-n play-v 14.000000', 'drip-v rusty-j 14.000000', 'arrow-n boxer-n 14.000000', 'basket-n moss-n 14.000000', 'pin-n wing-n 14.000000', 'apartment-n valley-n 14.000000', 'guy-n poodle-n 14.000000', 'seagull-n urban-j 14.000000', 'dessert-n tomato-n 14.000000', 'egg-n family-n 14.000000', 'aircraft-n guy-n 14.000000', 'dark-j flamingo-n 14.000000', 'cheerleader-n scenery-n 14.000000', 'pink-j shade-n 14.000000', 'couple-n outdoor-j 14.000000', 'garden-n smoke-n 14.000000', 'glass-n mill-n 14.000000', 'race-n square-j 14.000000', 'paper-n vine-n 14.000000', 'smile-n stand-v 14.000000', 'frost-n summer-n 14.000000', 'bay-n parking-n 14.000000', 'kiss-n sit-v 14.000000', 'monkey-n oak-n 14.000000', 'bead-n redhead-n 14.000000', 'animal-n hand-n 14.000000', 'cute-j music-n 14.000000', 'downtown-j hockey-n 14.000000', 'dead-j guy-n 14.000000', 'aircraft-n asphalt-n 14.000000', 'magazine-n run-v 14.000000', 'flight-n rain-n 14.000000', 'bathroom-n garden-n 14.000000', 'door-n skyscraper-n 14.000000', 'makeup-n old-j 14.000000', 'game-n sign-v 14.000000', 'dead-j face-n 14.000000', 'friend-n sexy-j 14.000000', 'flower-n interior-n 14.000000', 'bag-n wire-n 14.000000', 'game-n goat-n 14.000000', 'note-n rally-n 14.000000', 'stair-n steel-n 14.000000', 'diamond-n stencil-n 14.000000', 'nature-n tv-n 14.000000', 'happy-j post-v 14.000000', 'abstract-j rally-n 14.000000', 'party-n sailing-n 14.000000', 'beard-n kitty-n 14.000000', 'eat-v seagull-n 14.000000', 'building-n sandwich-n 14.000000', 'belly-n black-j 14.000000', 'leave-v walk-v 14.000000', 'dark-j stripe-n 14.000000', 'ford-n valley-n 14.000000', 'insect-n stork-n 14.000000', 'animal-n mural-n 14.000000', 'leather-n weed-n 14.000000', 'pub-n wash-v 14.000000', 'leave-v play-v 14.000000', 'cop-n gravestone-n 14.000000', 'book-n building-n 14.000000', 'happy-j walk-v 14.000000', 'colorful-j lab-n 14.000000', 'flag-n quote-n 14.000000', 'sink-v time-n 14.000000', 'friend-n sit-v 14.000000', 'lantern-n oak-n 14.000000', 'sit-v smile-n 14.000000', 'cottage-n outfit-n 14.000000', 'downtown-j lock-v 14.000000', 'pet-n poster-n 14.000000', 'industrial-j lake-n 14.000000', 'lick-v sit-v 14.000000', 'pool-n rust-n 14.000000', 'stripe-n train-n 14.000000', 'beef-n downtown-j 13.000000', 'blonde-j eye-n 13.000000', 'lady-n sunset-n 13.000000', 'feel-v stop-v 13.000000', 'old-j seat-n 13.000000', 'dirty-j happy-j 13.000000', 'ruin-n shore-n 13.000000', 'black-j paw-n 13.000000', 'egg-n lego-n 13.000000', 'bear-v play-v 13.000000', 'black-j pigeon-n 13.000000', 'feather-n reptile-n 13.000000', 'gymnastics-n port-n 13.000000', 'mom-n snowman-n 13.000000', 'dirty-j haircut-n 13.000000', 'party-n seat-n 13.000000', 'lily-n pig-n 13.000000', 'dirty-j hang-v 13.000000', 'guy-n wire-n 13.000000', 'orange-j shop-n 13.000000', 'cactus-n fall-v 13.000000', 'circle-n sport-n 13.000000', 'redhead-n reflection-n 13.000000', 'cafe-n reflection-n 13.000000', 'outfit-n play-v 13.000000', 'bar-n female-j 13.000000', 'belly-n dirty-j 13.000000', 'rope-n train-n 13.000000', 'boardwalk-n drop-v 13.000000', 'abstract-j candle-n 13.000000', 'church-n soldier-n 13.000000', 'boxer-n reflection-n 13.000000', 'crystal-n silhouette-n 13.000000', 'feel-v guy-n 13.000000', 'pattern-n pier-n 13.000000', 'downtown-j field-n 13.000000', 'beer-n wild-j 13.000000', 'hang-v happy-j 13.000000', 'rope-n shore-n 13.000000', 'airplane-n camera-n 13.000000', 'button-n flower-n 13.000000', 'frozen-j shop-n 13.000000', 'curl-v lick-v 13.000000', 'sunny-j zoo-n 13.000000', 'people-n stop-v 13.000000', 'bucket-n insect-n 13.000000', 'fence-n friend-n 13.000000', 'can-n sketch-n 13.000000', 'frozen-j pebble-n 13.000000', 'ceramic-j live-v 13.000000', 'day-n horse-n 13.000000', 'bear-v boxer-n 13.000000', 'iris-n necklace-n 13.000000', 'lighting-n person-n 13.000000', 'boot-n cliff-n 13.000000', 'landscape-n umbrella-n 13.000000', 'man-n transformer-n 13.000000', 'dark-j sand-n 13.000000', 'ruin-n swimsuit-n 13.000000', 'abstract-j rose-n 13.000000', 'guy-n gymnastics-n 12.000000', 'grass-n ruin-n 12.000000', 'lighting-n stone-n 12.000000', 'porch-n scooter-n 12.000000', 'colour-n wild-j 12.000000', 'crane-n stair-n 12.000000', 'shore-n tear-n 12.000000', 'cactus-n porch-n 12.000000', 'belly-n draw-v 12.000000', 'fabric-n photo-n 12.000000', 'lamb-n lantern-n 12.000000', 'owl-n rocket-n 12.000000', 'party-n scooter-n 12.000000', 'display-n scratch-n 12.000000', 'ball-n curl-v 12.000000', 'cookie-n peel-n 12.000000', 'couple-n post-v 12.000000', 'field-n red-j 12.000000', 'theatre-n wolf-n 12.000000', 'blue-j swing-n 12.000000', 'guy-n happy-j 12.000000', 'quote-n santa-n 12.000000', 'dude-n feel-v 12.000000', 'bath-n wine-n 12.000000', 'brown-j wet-j 12.000000', 'kiss-n stop-v 12.000000', 'husky-n match-n 12.000000', 'cocktail-n garage-n 12.000000', 'face-n stand-v 12.000000', 'kid-n stop-v 12.000000', 'boxer-n diner-n 12.000000', 'patio-n sleep-v 12.000000', 'city-n family-n 12.000000', 'drop-v rusty-j 12.000000', 'parade-n table-n 12.000000', 'dawn-n drug-n 12.000000', 'design-n orange-j 12.000000', 'lunch-n sunshine-n 12.000000', 'dirty-j dude-n 12.000000', 'fun-n tear-n 12.000000', 'bikini-n ivy-n 12.000000', 'step-n swimsuit-n 12.000000', 'frog-n poppy-n 12.000000', 'cross-n pub-n 12.000000', 'frost-n lily-n 12.000000', 'curve-n outdoor-j 12.000000', 'collage-n stream-n 12.000000', 'twig-n underground-j 12.000000', 'chair-n holiday-n 12.000000', 'coffee-n sun-n 12.000000', 'lighting-n sleep-v 12.000000', 'mill-n wild-j 12.000000', 'circle-n wig-n 12.000000', 'highway-n squirrel-n 12.000000', 'pin-n truck-n 12.000000', 'boxer-n swimming-n 12.000000', 'shore-n small-j 12.000000', 'punk-n vinyl-n 12.000000', 'number-n web-n 12.000000', 'brown-j demolition-n 12.000000', 'interior-n skyline-n 12.000000', 'breakfast-n floor-n 12.000000', 'aerial-j clown-n 12.000000', 'hat-n peel-n 12.000000', 'baseball-n rainbow-n 12.000000', 'dude-n happy-j 12.000000', 'foot-n mural-n 12.000000', 'creature-n grey-j 12.000000', 'cross-n outfit-n 12.000000', 'leave-v smile-n 11.000000', 'fishing-n rainbow-n 11.000000', 'bathroom-n dude-n 11.000000', 'paint-v puddle-n 11.000000', 'skating-n sticker-n 11.000000', 'dome-n uniform-j 11.000000', 'lawn-n sleep-v 11.000000', 'office-n sun-n 11.000000', 'military-j reflection-n 11.000000', 'fashion-n handwriting-n 11.000000', 'cop-n ruin-n 11.000000', 'blur-v metro-n 11.000000', 'smile-n stop-v 11.000000', 'cute-j lick-v 11.000000', 'cross-n mug-n 11.000000', 'concrete-j pin-n 11.000000', 'cigarette-n hotel-n 11.000000', 'airplane-n market-n 11.000000', 'architecture-n yellow-j 11.000000', 'handle-v terrier-n 11.000000', 'patio-n woman-n 11.000000', 'green-j gull-n 11.000000', 'dew-n parrot-n 11.000000', 'country-n hang-v 11.000000', 'dude-n hang-v 11.000000', 'stripe-n tank-n 11.000000', 'hang-v tear-n 11.000000', 'crochet-n family-n 11.000000', 'cute-j post-v 11.000000', 'machine-n sketch-n 11.000000', 'feel-v haircut-n 11.000000', 'match-n moss-n 11.000000', 'art-n sailing-n 11.000000', 'foliage-n restaurant-n 11.000000', 'tea-n village-n 11.000000', 'branch-n feline-j 11.000000', 'day-n plane-n 11.000000', 'gold-n idea-n 11.000000', 'moon-n mushroom-n 11.000000', 'interior-n tall-j 11.000000', 'mallard-n portrait-n 11.000000', 'live-v stitch-n 11.000000', 'fun-n morning-n 11.000000', 'drip-v rust-n 11.000000', 'fun-n stop-v 11.000000', 'gull-n mill-n 11.000000', 'dirty-j friend-n 11.000000', 'blue-j hand-n 11.000000', 'bucket-n curve-n 11.000000', 'patio-n swan-n 11.000000', 'body-n miniature-j 11.000000', 'cafe-n child-n 11.000000', 'belly-n stripe-n 11.000000', 'mural-n taxi-n 11.000000', 'furniture-n man-n 11.000000', 'bead-n library-n 11.000000', 'daffodil-n wool-n 11.000000', 'eat-v shade-n 11.000000', 'collection-n jellyfish-n 11.000000', 'country-n elephant-n 11.000000', 'line-n temple-n 11.000000', 'bead-n chess-n 11.000000', 'skirt-n wig-n 11.000000', 'daisy-n flood-n 11.000000', 'camera-n rally-n 11.000000', 'happy-j sit-v 11.000000', 'bottle-n construction-n 11.000000', 'auto-n bright-j 11.000000', 'computer-n railway-n 11.000000', 'night-n sit-v 11.000000', 'hair-n lizard-n 11.000000', 'happy-j lick-v 11.000000', 'jump-n sunlight-n 11.000000', 'desert-n smoke-n 11.000000', 'chopper-n window-n 11.000000', 'leave-v rusty-j 11.000000', 'hang-v stop-v 11.000000', 'animal-n sandwich-n 11.000000', 'cute-j dirty-j 11.000000', 'cafe-n draw-v 11.000000', 'boxer-n pyramid-n 11.000000', 'arm-n television-n 10.000000', 'feel-v hang-v 10.000000', 'asphalt-n moon-n 10.000000', 'dusk-n skirt-n 10.000000', 'car-n skull-n 10.000000', 'leave-v sit-v 10.000000', 'outfit-n rock-n 10.000000', 'mom-n stop-v 10.000000', 'drip-v round-n 10.000000', 'friend-n stop-v 10.000000', 'asphalt-n water-n 10.000000', 'sit-v tear-n 10.000000', 'cafe-n spiral-n 10.000000', 'ad-n bacon-n 10.000000', 'green-j phone-n 10.000000', 'duck-n outfit-n 10.000000', 'coast-n zebra-n 10.000000', 'breakfast-n makeup-n 10.000000', 'purple-j stripe-n 10.000000', 'clothes-n skyline-n 10.000000', 'step-n wind-n 10.000000', 'portrait-n rocket-n 10.000000', 'break-n glitter-v 10.000000', 'construction-n sailing-n 10.000000', 'boy-n gate-n 10.000000', 'lens-n storm-n 10.000000', 'orange-j school-n 10.000000', 'shirt-n show-n 10.000000', 'gasoline-n pepper-n 10.000000', 'drug-n sing-v 10.000000', 'sticker-n track-n 10.000000', 'furniture-n nature-n 10.000000', 'play-v rail-n 10.000000', 'rusty-j stand-v 10.000000', 'military-j wasp-n 10.000000', 'port-n squirrel-n 10.000000', 'grape-n rainbow-n 10.000000', 'flood-n neon-n 10.000000', 'morning-n tear-n 10.000000', 'memorial-n rope-n 10.000000', 'bright-j rusty-j 10.000000', 'home-n wet-j 10.000000', 'feather-n sunflower-n 10.000000', 'house-n stop-v 10.000000', 'plant-n skate-n 10.000000', 'cocktail-n dandelion-n 10.000000', 'airport-n foot-n 10.000000', 'display-n pond-n 10.000000', 'alley-n bloom-n 10.000000', 'escalator-n redhead-n 10.000000', 'caterpillar-n paint-v 10.000000', 'bacon-n wild-j 10.000000', 'stand-v tear-n 10.000000', 'collar-n tiger-n 10.000000', 'car-n hawk-n 10.000000', 'burn-v reading-n 10.000000', 'cigarette-n live-v 10.000000', 'footprint-n scooter-n 10.000000', 'barn-n mug-n 10.000000', 'bacon-n guy-n 10.000000', 'keyboard-n soldier-n 10.000000', 'cute-j sit-v 10.000000', 'track-n yellow-j 10.000000', 'bag-n dude-n 10.000000', 'lady-n stop-v 10.000000', 'arrow-n mural-n 10.000000', 'jacket-n stream-n 10.000000', 'lab-n rusty-j 10.000000', 'jaguar-n storm-n 10.000000', 'dirty-j smile-n 10.000000', 'friend-n rusty-j 10.000000', 'morning-n stop-v 10.000000', 'cemetery-n male-n 10.000000', 'jump-n stitch-n 10.000000', 'friend-n leave-v 10.000000', 'family-n hawk-n 10.000000', 'monster-n rock-n 10.000000', 'feel-v time-n 10.000000', 'face-n hang-v 10.000000', 'pizza-n railway-n 10.000000', 'cross-n shopping-n 10.000000', 'guy-n hang-v 10.000000', 'craft-n van-n 10.000000', 'art-n beer-n 9.000000', 'beard-n flamingo-n 9.000000', 'monster-n shell-n 9.000000', 'bench-n mask-n 9.000000', 'club-n river-n 9.000000', 'boxer-n child-n 9.000000', 'fungus-n leather-n 9.000000', 'lick-v stop-v 9.000000', 'creature-n reading-n 9.000000', 'ivy-n urban-j 9.000000', 'bed-n candy-n 9.000000', 'feel-v spiral-n 9.000000', 'hockey-n sign-v 9.000000', 'daughter-n pub-n 9.000000', 'idea-n rusty-j 9.000000', 'lighting-n man-n 9.000000', 'dude-n post-v 9.000000', 'mill-n puddle-n 9.000000', 'santa-n table-n 9.000000', 'action-n whisker-n 9.000000', 'eat-v web-n 9.000000', 'hot-j winter-n 9.000000', 'dog-n silver-n 9.000000', 'lip-n run-v 9.000000', 'porch-n pug-n 9.000000', 'bird-n pregnancy-n 9.000000', 'camera-n crow-n 9.000000', 'eat-v truck-n 9.000000', 'lick-v marble-n 9.000000', 'rabbit-n stop-v 9.000000', 'paper-n railway-n 9.000000', 'poster-n tank-n 9.000000', 'clothes-n transformer-n 9.000000', 'smoking-n sunny-j 9.000000', 'cactus-n leg-n 9.000000', 'hold-v theatre-n 9.000000', 'arm-n outdoor-j 9.000000', 'lighting-n panda-n 9.000000', 'punk-n toe-n 9.000000', 'branch-n protest-n 9.000000', 'daughter-n graphic-j 9.000000', 'air-n fruit-n 9.000000', 'book-n copper-n 9.000000', 'night-n sticker-n 9.000000', 'explosion-n table-n 9.000000', 'snake-n strawberry-n 9.000000', 'dragon-n drop-v 9.000000', 'dog-n sailing-n 9.000000', 'burn-v ripple-n 9.000000', 'clock-n pink-j 9.000000', 'kitten-n lingerie-n 9.000000', 'abandon-v frost-n 9.000000', 'chicken-n star-n 9.000000', 'seed-n stair-n 9.000000', 'leave-v night-n 9.000000', 'small-j valley-n 9.000000', 'green-j number-n 9.000000', 'leave-v morning-n 9.000000', 'lock-v mannequin-n 9.000000', 'shade-n whisker-n 9.000000', 'collar-n garbage-n 9.000000', 'ink-n organ-n 9.000000', 'poppy-n store-n 9.000000', 'smoking-n vine-n 9.000000', 'flame-n word-n 9.000000', 'daffodil-n frost-n 9.000000', 'dancer-n rusty-j 9.000000', 'canal-n coffee-n 9.000000', 'camera-n mallard-n 9.000000', 'noodle-n pigeon-n 9.000000', 'couple-n square-j 9.000000', 'rainbow-n whale-n 9.000000', 'fly-v keyboard-n 9.000000', 'soup-n view-n 9.000000', 'goat-n pebble-n 9.000000', 'abandon-v button-n 9.000000', 'belly-n dark-j 9.000000', 'diamond-n parade-n 9.000000', 'horse-n sweet-j 9.000000', 'ancient-j pod-n 9.000000', 'banana-n foot-n 9.000000', 'shed-v traffic-n 9.000000', 'bucket-n morning-n 9.000000', 'bucket-n duck-n 8.000000', 'dessert-n eye-n 8.000000', 'cold-j flag-n 8.000000', 'skin-n television-n 8.000000', 'bedroom-n feline-j 8.000000', 'palm-n traffic-n 8.000000', 'necklace-n snow-n 8.000000', 'lick-v origami-n 8.000000', 'protest-n tile-n 8.000000', 'beetle-n chocolate-n 8.000000', 'monkey-n pumpkin-n 8.000000', 'cop-n music-n 8.000000', 'beard-n sport-n 8.000000', 'gasoline-n summer-n 8.000000', 'footprint-n holiday-n 8.000000', 'abandon-v crane-n 8.000000', 'car-n pig-n 8.000000', 'grave-n santa-n 8.000000', 'iron-n splash-n 8.000000', 'dirt-n gymnastics-n 8.000000', 'orange-j wet-j 8.000000', 'ceramic-j ocean-n 8.000000', 'vintage-j zebra-n 8.000000', 'hair-n shore-n 8.000000', 'lingerie-n underground-j 8.000000', 'marble-n postcard-n 8.000000', 'fish-n leg-n 8.000000', 'book-n smoking-n 8.000000', 'kiss-n rusty-j 8.000000', 'canal-n number-n 8.000000', 'kitchen-n sleep-v 8.000000', 'cherry-n lamb-n 8.000000', 'bag-n cop-n 8.000000', 'leaf-n moon-n 8.000000', 'dude-n time-n 8.000000', 'kitchen-n outfit-n 8.000000', 'garbage-n jean-n 8.000000', 'bedroom-n downtown-j 8.000000', 'grass-n ski-n 8.000000', 'day-n hold-v 8.000000', 'mug-n vehicle-n 8.000000', 'lighting-n small-j 8.000000', 'sea-n sing-v 8.000000', 'computer-n farm-n 8.000000', 'feline-j pumpkin-n 8.000000', 'jean-n map-n 8.000000', 'dirty-j eagle-n 8.000000', 'book-n ceramic-j 8.000000', 'van-n vine-n 8.000000', 'desert-n roof-n 8.000000', 'seagull-n tag-n 8.000000', 'jewelry-n muscle-n 8.000000', 'milk-n outdoor-j 8.000000', 'guy-n rusty-j 8.000000', 'chocolate-n jellyfish-n 8.000000', 'boxer-n stair-n 8.000000', 'jaguar-n pier-n 7.000000', 'nut-n waterfall-n 7.000000', 'bread-n chair-n 7.000000', 'goat-n vinyl-n 7.000000', 'kitten-n rain-n 7.000000', 'hang-v smile-n 7.000000', 'bikini-n sculpture-n 7.000000', 'bible-n dirt-n 7.000000', 'portrait-n underground-j 7.000000', 'clock-n stripe-n 7.000000', 'bud-n floor-n 7.000000', 'air-n knit-v 7.000000', 'idea-n stop-v 7.000000', 'haircut-n stop-v 7.000000', 'storm-n sweet-j 7.000000', 'auto-n santa-n 7.000000', 'marble-n sing-v 7.000000', 'drive-n ear-n 7.000000', 'bear-v subway-n 7.000000', 'pumpkin-n road-n 7.000000', 'makeup-n race-n 7.000000', 'wash-v web-n 7.000000', 'haircut-n pyramid-n 7.000000', 'blonde-j rock-n 7.000000', 'belly-n field-n 7.000000', 'mammal-n yellow-j 7.000000', 'paint-v sing-v 7.000000', 'cat-n locomotive-n 7.000000', 'dead-j sidewalk-n 7.000000', 'angel-n pod-n 7.000000', 'eat-v underwater-j 7.000000', 'makeup-n square-j 7.000000', 'cigarette-n tile-n 7.000000', 'museum-n scratch-n 7.000000', 'butterfly-n stadium-n 7.000000', 'graveyard-n porch-n 7.000000', 'flame-n peacock-n 7.000000', 'chopper-n poppy-n 7.000000', 'rusty-j tear-n 7.000000', 'bloom-n friend-n 7.000000', 'gun-n jaguar-n 7.000000', 'guy-n stop-v 7.000000', 'cloud-n kitten-n 7.000000', 'pillow-n stone-n 7.000000', 'stocking-n tomato-n 7.000000', 'frost-n protest-n 7.000000', 'sign-v stocking-n 7.000000', 'angel-n asphalt-n 7.000000', 'ski-n skirt-n 7.000000', 'cat-n purple-j 7.000000', 'diner-n muscle-n 7.000000', 'marble-n sunglasses-n 7.000000', 'berry-n fly-v 7.000000', 'chocolate-n rock-n 7.000000', 'airplane-n guitar-n 7.000000', 'bread-n ocean-n 7.000000', 'bay-n chipmunk-n 7.000000', 'tall-j wool-n 7.000000', 'restaurant-n violet-n 7.000000', 'drop-v fun-n 7.000000', 'purple-j twig-n 7.000000', 'cemetery-n cone-n 7.000000', 'face-n stop-v 7.000000', 'dude-n stop-v 7.000000', 'bicycle-n handwriting-n 7.000000', 'chapel-n dusk-n 7.000000', 'cute-j twig-n 7.000000', 'dragon-n oak-n 7.000000', 'drug-n reflection-n 7.000000', 'apple-n relax-v 7.000000', 'bakery-n panorama-n 7.000000', 'mallard-n poster-n 7.000000', 'snake-n taxi-n 7.000000', 'dessert-n head-n 7.000000', 'bear-v hockey-n 7.000000', 'puddle-n red-j 7.000000', 'brick-n dress-n 7.000000', 'building-n zombie-n 7.000000', 'neon-n tank-n 7.000000', 'bible-n cottage-n 7.000000', 'bath-n panorama-n 7.000000', 'automobile-n fabric-n 7.000000', 'gun-n picture-n 7.000000', 'cow-n table-n 6.000000', 'bear-v construction-n 6.000000', 'dye-n kiss-n 6.000000', 'baseball-n bear-v 6.000000', 'crab-n grave-n 6.000000', 'craft-n soup-n 6.000000', 'lock-v misty-j 6.000000', 'horse-n interior-n 6.000000', 'grass-n stop-v 6.000000', 'jellyfish-n punk-n 6.000000', 'parade-n salad-n 6.000000', 'reptile-n vacation-n 6.000000', 'clown-n flood-n 6.000000', 'aerial-j violet-n 6.000000', 'crab-n ink-n 6.000000', 'canyon-n pizza-n 6.000000', 'butterfly-n leave-v 6.000000', 'hamster-n party-n 6.000000', 'museum-n swim-v 6.000000', 'lego-n rodent-n 6.000000', 'branch-n lego-n 6.000000', 'game-n husky-n 6.000000', 'camel-n highway-n 6.000000', 'baseball-n cheetah-n 6.000000', 'stripe-n weather-n 6.000000', 'journal-n squirrel-n 6.000000', 'cake-n rusty-j 6.000000', 'bacon-n view-n 6.000000', 'dandelion-n stand-v 6.000000', 'cheetah-n flame-n 6.000000', 'abstract-j vehicle-n 6.000000', 'party-n sink-v 6.000000', 'floor-n transformer-n 6.000000', 'amphibian-n berry-n 6.000000', 'marble-n monkey-n 6.000000', 'jump-n salad-n 6.000000', 'subway-n valentine-n 6.000000', 'baseball-n cactus-n 6.000000', 'ancient-j poster-n 6.000000', 'grass-n skull-n 6.000000', 'cattle-n web-n 6.000000', 'drive-n lego-n 6.000000', 'fly-v sexy-j 6.000000', 'ink-n tropical-j 6.000000', 'pyramid-n swimsuit-n 6.000000', 'chess-n sleep-v 6.000000', 'bag-n wild-j 6.000000', 'chapel-n whisker-n 6.000000', 'chair-n word-n 6.000000', 'angel-n construction-n 6.000000', 'exhibition-n soup-n 6.000000', 'kitten-n travel-n 6.000000', 'swim-v vehicle-n 6.000000', 'costume-n ocean-n 6.000000', 'pigeon-n reading-n 6.000000', 'origami-n stadium-n 6.000000', 'animal-n candy-n 6.000000', 'happy-j stop-v 5.000000', 'insect-n mom-n 5.000000', 'canyon-n piano-n 5.000000', 'leather-n swan-n 5.000000', 'goose-n outfit-n 5.000000', 'sunglasses-n weed-n 5.000000', 'play-v wine-n 5.000000', 'monkey-n restaurant-n 5.000000', 'goose-n locomotive-n 5.000000', 'garage-n mammal-n 5.000000', 'drug-n wolf-n 5.000000', 'graveyard-n pug-n 5.000000', 'chair-n ipod-n 5.000000', 'rice-n ticket-n 5.000000', 'mammal-n rope-n 5.000000', 'hill-n rust-n 5.000000', 'paw-n protest-n 5.000000', 'petal-n pug-n 5.000000', 'interior-n mushroom-n 5.000000', 'chocolate-n squirrel-n 5.000000', 'mammal-n write-v 5.000000', 'reading-n seagull-n 5.000000', 'parking-n photographer-n 5.000000', 'tea-n whisker-n 5.000000', 'cactus-n gasoline-n 5.000000', 'kitchen-n wedding-n 5.000000', 'chocolate-n wig-n 5.000000', 'hang-v mom-n 5.000000', 'dragonfly-n piano-n 5.000000', 'leather-n sunshine-n 5.000000', 'handwriting-n pig-n 5.000000', 'brick-n rabbit-n 5.000000', 'burger-n mountain-n 5.000000', 'girl-n morning-n 5.000000', 'canal-n silhouette-n 5.000000', 'advertisement-n pond-n 5.000000', 'paw-n theatre-n 5.000000', 'raspberry-n write-v 5.000000', 'family-n red-j 5.000000', 'concrete-j swan-n 5.000000', 'bedroom-n canyon-n 5.000000', 'breakfast-n staircase-n 5.000000', 'flame-n sidewalk-n 5.000000', 'carrot-n city-n 5.000000', 'ipod-n rope-n 5.000000', 'lick-v rusty-j 5.000000', 'meat-n pond-n 5.000000', 'female-j machine-n 5.000000', 'live-v makeup-n 5.000000', 'piano-n wolf-n 5.000000', 'girl-n wind-n 5.000000', 'frog-n subway-n 5.000000', 'map-n weed-n 5.000000', 'bike-n flame-n 5.000000', 'dew-n engine-n 5.000000', 'cake-n library-n 5.000000', 'carnival-n wool-n 5.000000', 'bottle-n library-n 5.000000', 'eat-v hair-n 5.000000', 'dragon-n furniture-n 5.000000', 'skull-n storm-n 5.000000', 'rodent-n smile-n 5.000000', 'punk-n skyscraper-n 5.000000', 'gun-n pizza-n 4.000000', 'female-j square-j 4.000000', 'pub-n snowman-n 4.000000', 'meat-n moon-n 4.000000', 'potato-n skating-n 4.000000', 'dragonfly-n wine-n 4.000000', 'flight-n whisker-n 4.000000', 'boxer-n lighthouse-n 4.000000', 'fungus-n wedding-n 4.000000', 'lick-v pier-n 4.000000', 'mirror-n raspberry-n 4.000000', 'bike-n hummingbird-n 4.000000', 'key-j misty-j 4.000000', 'cafe-n frog-n 4.000000', 'soup-n wool-n 4.000000', 'carrot-n memorial-n 4.000000', 'lion-n square-j 4.000000', 'bucket-n girl-n 4.000000', 'feline-j nut-n 4.000000', 'gun-n quote-n 4.000000', 'furniture-n pizza-n 4.000000', 'goose-n stencil-n 4.000000', 'chicken-n knit-v 4.000000', 'abstract-j frog-n 4.000000', 'ceiling-n mug-n 4.000000', 'fish-n rocket-n 4.000000', 'flamingo-n office-n 4.000000', 'rabbit-n sphere-n 4.000000', 'ice-n sheep-n 4.000000', 'car-n tongue-n 4.000000', 'bracelet-n mountain-n 4.000000', 'cocktail-n write-v 4.000000', 'lego-n weather-n 4.000000', 'cigarette-n skating-n 3.000000', 'happy-j rusty-j 3.000000', 'tomato-n whale-n 3.000000', 'chess-n cigarette-n 3.000000', 'fish-n theatre-n 3.000000', 'donut-n panda-n 3.000000', 'hot-j zombie-n 3.000000', 'machine-n pond-n 3.000000', 'guitar-n nude-j 3.000000', 'giraffe-n mist-n 3.000000', 'bread-n cliff-n 3.000000', 'bible-n misty-j 3.000000', 'construction-n violet-n 3.000000', 'cheetah-n soup-n 3.000000', 'puppy-n skyline-n 3.000000', 'child-n ford-n 3.000000', 'cheetah-n phone-n 3.000000', 'explosion-n stencil-n 3.000000', 'carrot-n design-n 2.000000', 'jellyfish-n rally-n 2.000000', 'military-j tomato-n 2.000000', 'gun-n stair-n 2.000000', 'cafe-n lizard-n 2.000000', 'post-v tulip-n 2.000000', 'grave-n hat-n 2.000000', 'apple-n cute-j 2.000000', 'angel-n gasoline-n 1.000000', 'giraffe-n harbor-n 1.000000', 'feather-n truck-n 1.000000', 'festival-n whisker-n 1.000000', 'muscle-n tulip-n 1.000000', 'bikini-n pizza-n 1.000000', 'bakery-n zebra-n 0.000000', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyG110Xqx09Z"
      },
      "source": [
        "df = pd.DataFrame(columns=(['word_1', '1_in_vocab',\n",
        "                            'word_2', '2_in_vocab',\n",
        "                            'MEN_score', 'EMB_cos']))\n",
        "\n",
        "for line in dataset:\n",
        "    temp_line = line.split()\n",
        "    try:\n",
        "        first_word = temp_line[0].split('-')[0]\n",
        "        second_word = temp_line[1].split('-')[0]\n",
        "        \n",
        "        df = df.append({'word_1': first_word,\n",
        "                        '1_in_vocab': first_word in model.wv.vocab,\n",
        "                        'word_2': second_word,\n",
        "                        '2_in_vocab': second_word in model.wv.vocab,\n",
        "                        'MEN_score':  temp_line[2],\n",
        "                        'EMB_cos': model.wv.similarity(first_word, second_word)},\n",
        "                        ignore_index=True)\n",
        "    except:\n",
        "\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fgZjzyHx09Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21f33ac4-b68b-4dd6-baab-952c6cf95878"
      },
      "source": [
        "print('MEN rows: ', df.size/len(df.columns))\n",
        "print('Dictionary size: ', len(model.wv.vocab))\n",
        "print('Total missing words: ', df[df['1_in_vocab'] == False].size + df[df['2_in_vocab'] == False].size) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MEN rows:  2682.0\n",
            "Dictionary size:  16822\n",
            "Total missing words:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQP3ZM-Dx09a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b8dac31-00dd-4f76-c2fc-769bfe3de279"
      },
      "source": [
        "# Normalizing the MEN_score\n",
        "\n",
        "MEN_score = df.MEN_score.values\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(MEN_score.reshape(-1, 1))\n",
        "df['norm_MEN_score'] = pd.DataFrame(x_scaled)\n",
        "\n",
        "print(stats.spearmanr(df.norm_MEN_score, df.EMB_cos))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SpearmanrResult(correlation=0.40683729980717315, pvalue=1.8937703629283692e-107)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_coZHiTx09a"
      },
      "source": [
        "# Model(s) with CADE\n",
        "\n",
        "We use CADE to generate **aligned** word embeddings (comparable even if coming from different sources).\n",
        "\n",
        "CADE uses the Compass to generate a DSM for each story.\n",
        "\n",
        "CADE saves the model files in the folder \"CADE/models\".\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5NgWHcEx09b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fa904df-2baf-4ac8-fc0e-5fb18267df38"
      },
      "source": [
        "\n",
        "aligner = CADE(size=size,\n",
        "               sg=model_type,\n",
        "               min_count=min_count,\n",
        "               window=window,\n",
        "               opath=PATH + 'CADE/models/model_'+str(min_count)+'_'+str(size))\n",
        "\n",
        "# train on the compass: the text should be the concatenation of the text from the slices\n",
        "aligner.train_compass(PATH + \"CADE/compass.txt\", overwrite=False) # keep an eye on the overwrite behaviour\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training the compass from scratch.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/smart_open/smart_open_lib.py:410: UserWarning:\n",
            "\n",
            "This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jydZnBzfx09b",
        "scrolled": true
      },
      "source": [
        "# After having created the Compass we train a model on each corpus (found in the stories folder)\n",
        "slice_list = []\n",
        "path = PATH + 'CADE/training'\n",
        "folder = os.listdir(path)\n",
        "print(sorted(folder))\n",
        "\n",
        "for story in sorted(folder):\n",
        "    if story[0].isupper():\n",
        "        slice_list.append(aligner.train_slice(path+'/'+story, save=True))\n",
        "\n",
        "print(f'Number of models trained: {len(slice_list)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAe37ly-X6AB"
      },
      "source": [
        "# Word-Form Matrix\n",
        " \n",
        "In order to deploy the form-meaning mapping functions we need to vectorize the orthographic form of the names we want to investigate. \n",
        "\n",
        "To this end, we use letter n-grams to featurize the name of the characters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSC4wXhZhyDz"
      },
      "source": [
        "## n-grams featurization Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmWH4XPDnx1h"
      },
      "source": [
        "class FormMatrix:\n",
        "   \"\"\"\n",
        "  Takes a list of words to be vectorized using letter ngrams to then generate form vectors for each word.\n",
        "\n",
        "  word_list : a list of words\n",
        "  n: the number of ngrams\n",
        "  map_dict: ngrams mapping\n",
        "\n",
        "  return word-form matrix, each row is a word, the columns are the number of unique ngrams\n",
        "  \"\"\"\n",
        "  def __init__(self, word_list, n, map_dict = None):\n",
        "    self.word_list = word_list\n",
        "    self.ngram_size = n\n",
        "    self.idx2word = {i: w for i, w in enumerate(self.word_list)}\n",
        "    self.word2idx = {w: i for i, w in enumerate(self.word_list)}\n",
        "    self.map_dict = map_dict\n",
        "    if not map_dict:\n",
        "      self.form_matrix, self.map_dict = self.ngrams_encoding(self.word_list, n)\n",
        "    else:\n",
        "      self.form_matrix, self.map_dict = self.ngrams_encoding(self.word_list, n, self.map_dict)\n",
        "\n",
        "\n",
        "  def ngram_featurizer(self, s, n):\n",
        "    \n",
        "    \"\"\"takes in a string and an integer defining the size of ngrams.\n",
        "     Returns the ngrams of desired size in the input string\"\"\"\n",
        "    if n == 1:\n",
        "        t = 1\n",
        "    else:\n",
        "        t = n-1\n",
        "    s = '#'*t + s + '#'*t\n",
        "    ngrams = [s[i:i+n] for i in range(len(s)-n+1)]\n",
        "    \n",
        "    return ngrams\n",
        "\n",
        "\n",
        "  \n",
        "  def ngrams_encoding(self, word_list, n, mapping=None):\n",
        "    \n",
        "    \"\"\"\n",
        "    Takes in a list of strings, an integer indicating the character ngrams' size,\n",
        "    and a dictionary mapping ngrams to numerical indices. If no dictionary is passed,\n",
        "    one is created inside the function.\n",
        "    The function outputs a 2d NumPy array with as many rows as there are strings in \n",
        "    the input list, and the mapping from ngrams to indices, representing the columns \n",
        "    of the NumPy array.\n",
        "    \"\"\"\n",
        "    \n",
        "    if not mapping:\n",
        "        all_ngrams = set()\n",
        "        for word in word_list:\n",
        "\n",
        "\n",
        "            all_ngrams = all_ngrams.union(set(self.ngram_featurizer(word, n)))\n",
        "    \n",
        "        mapping = {char: i for i, char in enumerate(all_ngrams)}\n",
        "    \n",
        "    matrix = np.zeros((len(word_list), len(mapping)))\n",
        "    for i, instance in enumerate(word_list):\n",
        "        for ngram in self.ngram_featurizer(instance, n):\n",
        "            try:\n",
        "                matrix[i, mapping[ngram]] += 1\n",
        "            except KeyError:\n",
        "                pass\n",
        "    \n",
        "    return matrix, mapping\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPSrUJraldel"
      },
      "source": [
        "## Creating Form Matrix\n",
        "\n",
        "Instatiating the Word-Form Matrix by feeding a clean version of the vocabulary (Compass). We have removed the name of the characters in order to avoid bias when estimating form-based semantic vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcnEH1kHDuia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34361f58-b355-422c-f698-2fef429955b5"
      },
      "source": [
        "w2v_clean_vocab = [word for word in words if not word.endswith(\"_char\") and word.isalpha()]\n",
        "\n",
        "# instatiating the FormMatrix\n",
        "ngram_size = 1\n",
        "FM = FormMatrix(w2v_clean_vocab, ngram_size)\n",
        "\n",
        "\n",
        "# the lenght of the vocab and the rows of the form matrix will be the same\n",
        "print(len(w2v_clean_vocab))\n",
        "\n",
        "FM.form_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15361\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15361, 27)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjsqmZtWhj7S"
      },
      "source": [
        "# Mapping Functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZyF4HN3hoZG"
      },
      "source": [
        "## Orthographic Semantic Consistency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtQ6mO0naKTy"
      },
      "source": [
        "def find_most_similar(TW, FM, k=5):\n",
        "  \"\"\"Calculates the most similar k words, given the target vector of a word. Returns the most similar words\n",
        "  inputs: target_word_form_matrix (TW)\n",
        "  general_word_form_matrix (FM)\n",
        "  number of neighbors (k)\n",
        "  \n",
        "  returns: list with k most similar words\"\"\"\n",
        "  most_similar = []\n",
        "  # calculating similarity and appending a tuple to most_similar\n",
        "  # tuple ->(similarity, word)\n",
        "  for idx, vector in enumerate(FM.form_matrix):\n",
        "    cosine_similarity = 1 - spatial.distance.cosine(TW.form_matrix, vector)\n",
        "    most_similar.append((cosine_similarity, FM.idx2word[idx]))\n",
        "  \n",
        "  # sorting ascending\n",
        "  most_similar = sorted(most_similar, reverse=True)\n",
        "\n",
        "  # making sure there isn't a case in which similarity is 1\n",
        "  most_similar = [(sim , name) for sim , name in most_similar if sim != 1]\n",
        "\n",
        "  # getting the similarity of neighbors at k index\n",
        "  k_distance = most_similar[k-1][0]\n",
        "  \n",
        "  # new list with only relevant words\n",
        "  k_similar = most_similar[:k]\n",
        "\n",
        "  # looping over a slice, excluding already added words \n",
        "  for w in most_similar[k:]:\n",
        "    # if similarity of current word == similarity of k neighbors\n",
        "    if w[0] == k_distance:\n",
        "      k_similar.append(w)\n",
        "    else:\n",
        "      break \n",
        "\n",
        "\n",
        "  return k_similar\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuBQSG2eiGea"
      },
      "source": [
        "def osc(target_s, model, FM, k):\n",
        "   \"\"\"\n",
        "  We return a form-based semantic vector by averaging semantic vectors of words with a similar orthographic form \n",
        "\n",
        "  target_s: input name string\n",
        "  model: semantic model to retrieve semantic vectors\n",
        "  FM: form matrix to retrive form vector\n",
        "  k: number of similar word (in form space) to include in the computation\n",
        "  \"\"\"\n",
        "  # form-encoding of target word\n",
        "  target_w = target_s.split()\n",
        "  TW = FormMatrix(target_w, FM.ngram_size, FM.map_dict)\n",
        "\n",
        "  k_similar = find_most_similar(TW=TW, FM=FM, k=k)\n",
        "  # sizes of the model\n",
        "  vectors_sum = np.zeros(model.vector_size)\n",
        "  sim_sum = 0\n",
        "  for sim, word in k_similar:\n",
        "    sim_sum += sim\n",
        "    print(\"most similar in form space: \", word, sim)\n",
        "\n",
        "    w2v_word = model.wv[word]\n",
        "    vectors_sum += (w2v_word*sim)\n",
        "\n",
        "\n",
        "  osc = vectors_sum/sim_sum\n",
        "  \n",
        "  return osc\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3eZ0cwghsuV"
      },
      "source": [
        "## Linear Discriminative Learning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1klj8rThlXs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b1317ad-1fb1-40bd-9286-d67d6d722531"
      },
      "source": [
        "FM.form_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15361, 5411)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUfQDPapUOMk",
        "outputId": "5842f695-8e5d-4535-9c32-456e9739e153"
      },
      "source": [
        "clean_compass_model.wv.vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16822, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMwkdG74Vq38"
      },
      "source": [
        "# WE MULTIPLY THE SEMANTIC MATRIX (S) BY THE INVERSE OF THE FORM MATRIX (F)\n",
        "# F and S MUST MUST HAVE SAME NUMBER OF ROWS\n",
        "# need to do some cleaning\n",
        "\n",
        "\n",
        "\n",
        "# clean the semantic matrix, excluding numbers and the annotated character names (ending with _char)\n",
        "# TRIMMING DIRTY WORDS, THAT IS CHARACHTER NAMES AND NON ALPHABETIC\n",
        "w2v_dirty_vocab = [word for word in words if word.endswith(\"_char\") or not word.isalpha()]\n",
        "\n",
        "ids_to_trim = [clean_compass_model.wv.vocab[w].index for w in w2v_dirty_vocab]\n",
        "\n",
        "for w in w2v_dirty_vocab:\n",
        "    del clean_compass_model.wv.vocab[w]\n",
        "\n",
        "clean_compass_model.wv.vectors = np.delete(clean_compass_model.wv.vectors, ids_to_trim, axis=0)\n",
        "clean_compass_model.wv.init_sims(replace=True)\n",
        "\n",
        "for i in sorted(ids_to_trim, reverse=True):\n",
        "    del(clean_compass_model.wv.index2word[i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx4xitYwVM3d",
        "outputId": "40b7901a-266b-437d-be00-5ec2cd0fb4b4"
      },
      "source": [
        "# the number of rows of the semantic matrix should now be equal to the the number of rows of the form matrix\n",
        "clean_compass_model.wv.vectors.shape\n",
        "print(FM.form_matrix.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15361, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEpCGENOd626"
      },
      "source": [
        "def ldl_mapping(FormM, w2v,):\n",
        "  \"\"\" \n",
        "  It calculates the inverse of the Word-Form Matrix to then compute a form-meaning mapping function.\n",
        "  param1: Word-Form Matrix, in which each word is a row\n",
        "  param2: word2vec model, in which each word is a row\n",
        "  the number of rows of the word-form matrix and of the w2v model matrix has to be the same\n",
        "  returns: a form-meaning mapping matrix, in with as many rows as colums in the Word-Form Matrix and as many columns as dimension in the w2v model  \"\"\"\n",
        "  # F = [(15361, 573)]; S = [(15361, 50)]\n",
        "  inv = np.linalg.pinv(FormM.form_matrix) # inverse of F -> [(573, 15361)]\n",
        "\n",
        "  # matrix multiplication [(573, 15361)] * [(15361, 50)]\n",
        "  ldl_mapping = np.matmul(inv, w2v.wv.vectors) # mapping matrix is -> (573, 50)\n",
        "  return ldl_mapping\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgsMU6ZGeKeQ"
      },
      "source": [
        "# we pass to the semantic matrix and the word-form matrix to genrate mapping matrix\n",
        "# we use it later when generating form-based semantic vectors\n",
        "linearDL_mapping = ldl_mapping(FormM=FM, w2v=clean_compass_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZoMa7H9etXm",
        "outputId": "745dbd9d-9a08-4021-8ec7-f775f8c439ff"
      },
      "source": [
        "linearDL_mapping.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5411, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuAaeYV2TWEu"
      },
      "source": [
        "def ldl(target_str, ldl_mapping, FormM):\n",
        "  \"\"\"\n",
        "  It generates a form-based semantic vector using Linear Discriminant Learning\n",
        "  param1: target name\n",
        "  param2: linear discriminant learning mapping matrix used to map the word-form to semantic dimensions\n",
        "  param3: Word-Form Matrix, to compute vectorization of target name\n",
        "  return form-based semantic vector\n",
        "  \"\"\"\n",
        "  # input is in form of list\n",
        "  target_w = target_str.split()\n",
        "\n",
        "  # vectorizing the target name in ngrams\n",
        "  # size of the vector is [(1, 573)]\n",
        "  TW = FormMatrix(target_w, FormM.ngram_size, FormM.map_dict)\n",
        "\n",
        "  # multiplying size vector with ldl mapping matrix\n",
        "  # [(1, 573)] * [(573, 50)]\n",
        "  ldl = np.matmul(TW.form_matrix, ldl_mapping)\n",
        "\n",
        "  # return a vector of size [(1, 50)]\n",
        "  return np.squeeze(ldl)\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xHbsNkMLwiA"
      },
      "source": [
        "# Generation of Form Based Semantic Vectors \n",
        "\n",
        "We deploy the form-meaning mapping functions in order to generated form-based semantic vectors from the orthographic form of character names.\n",
        "\n",
        "Form-based semantic vectors are saved in a pickle file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGPpjwTYlJsq"
      },
      "source": [
        "\n",
        "# PREPARING DATASET\n",
        "complete_df.loc[ 0 ,\"osc_vector\"] = 0\n",
        "\n",
        "complete_df.loc[ 0, \"ldl_vector\"] = 0\n",
        "\n",
        "complete_df[\"osc_vector\"] = complete_df[\"osc_vector\"].astype(object)\n",
        "complete_df[\"ldl_vector\"] = complete_df[\"ldl_vector\"].astype(object)\n",
        "\n",
        "for i in range(len(complete_df)):\n",
        "  full_name = complete_df.loc[i, \"full_name\"].lower()\n",
        "  #print(full_name, i)\n",
        "  name = complete_df.loc[i, \"full_name\"].lower().split()[0]\n",
        "  print(name, i)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gajjF8xYGt3"
      },
      "source": [
        "# APPENDING TO THE DATASET OSC & LDL VECTORS FOR EACH CHARACHTER\n",
        "for i in range(len(complete_df)):\n",
        "  # first name of character\n",
        "  name = complete_df.loc[i, \"full_name\"].lower().split()[0]\n",
        "  print(name, i)\n",
        "  # generate osc\n",
        "  osc_form_based = osc(target_s= name, model=compass_model, FM=FM, k=5)\n",
        "  # generate ldl\n",
        "  ldl_form_based = ldl(target_str=name , ldl_mapping=linearDL_mapping, FormM = FM)\n",
        "  complete_df[\"osc_vector\"][i] = osc_form_based\n",
        "  complete_df[\"ldl_vector\"][i] = ldl_form_based\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0OKJMNtNZEk"
      },
      "source": [
        "complete_df.to_pickle(PATH + \"complete_df.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leaFGGciJOJc"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "\n",
        "\n",
        "*   Semantic Neighborhood Density (SND)\n",
        "*   OSC and LDL vs centroid\n",
        "*   form-based vs context based\n",
        "*   Cosine similarity with words of interest.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spmaJRNXJREu"
      },
      "source": [
        "## SND on COMPASS & similarity of OSC and LDL to centroid\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hwhYAwHJUO4"
      },
      "source": [
        "def semantic_n_distance(w2v_model, target_vector, N = 5):\n",
        "  \"\"\" returns the semantic neighbor density of the target vector, given N most similar words in COMPASS semantic space\"\"\"\n",
        "  # get the most similar words to vector\n",
        "  similars =  w2v_model.wv.similar_by_vector(target_vector, topn=N)\n",
        "  print(similars)\n",
        "  # averaging over the similarity of the most similar\n",
        "  snd = np.mean([sim for _ , sim in similars])\n",
        "  return snd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNn6akDRbQ61"
      },
      "source": [
        "def diff_sim_wordlist(words_list_1, words_list_2, a_vector, centroid_v, a_model):\n",
        "  \"\"\"Return the diff between the sum of similarity of two word list, given a semantic vector and a w2vmodel \"\"\"\n",
        "  similarity_sum_1 = []\n",
        "  similarity_sum_2 = []\n",
        "  # looping over the first list\n",
        "  for w1 in words_list_1:\n",
        "    # get a semantic vector for each word\n",
        "    word_vector = a_model.wv[w1]\n",
        "    # calculates similarity with the semantic target vector given as a input\n",
        "    sim_vector = 1 - spatial.distance.cosine(a_vector, word_vector)\n",
        "    sim_centroid = 1 - spatial.distance.cosine(centroid_v, word_vector)\n",
        "    # add similarity to total\n",
        "    similarity_sum_1.append(sim_vector - sim_centroid) \n",
        "\n",
        "  # looping over the second list\n",
        "  for w2 in words_list_2:\n",
        "    # get a semantic vector for each word\n",
        "    word_vector = a_model.wv[w2]\n",
        "    # calculates similarity with the semantic target vector given as a input\n",
        "    sim_vector = 1 - spatial.distance.cosine(a_vector, word_vector)\n",
        "    sim_centroid = 1 - spatial.distance.cosine(centroid_v, word_vector)\n",
        "    # add similarity to total\n",
        "    similarity_sum_2.append(sim_vector - sim_centroid)\n",
        "\n",
        "  return np.mean(similarity_sum_1) - np.mean(similarity_sum_2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgdhxPGmLyw0"
      },
      "source": [
        "# APPENDING TO DATAFRAME SND FOR EACH CHARACTER IN COMPASS SPACE\n",
        "# getting centroid of the semantic space based on compass\n",
        "centroid = np.mean(compass_model.wv.vectors, axis=0)\n",
        "snd_df = pd.DataFrame(columns=[\"Class\", \"SND_OSC\", \"centroid_vs_OSC\", \"centroid_vs_LDL\", \"SND_LDL\"], dtype=float)\n",
        "\n",
        "for i in range(len(complete_df)):\n",
        "  Class = complete_df.loc[i, \"class\"]\n",
        "  # getting the form-based semantic vectors from the dataset\n",
        "  osc_vector = complete_df.loc[i, \"osc_vector\"]\n",
        "  ldl_vector = complete_df.loc[i, \"ldl_vector\"]\n",
        "  print(i)\n",
        "  #print(\"SND of: \", name)\n",
        "  # COMPUTING SND\n",
        "  osc_snd = semantic_n_distance(compass_model, osc_vector, N = 20)\n",
        "  ldl_snd = semantic_n_distance(compass_model, ldl_vector, N = 20)\n",
        "\n",
        "  # similarity between osc and ldl\n",
        "  osc_vs_ldl = 1 - spatial.distance.cosine(osc_vector, ldl_vector)\n",
        "  #distance to centroid\n",
        "  centroid_vs_osc = 1 - spatial.distance.cosine(centroid, osc_vector)\n",
        "  centroid_vs_ldl = 1 - spatial.distance.cosine(centroid, ldl_vector)\n",
        "  # appending to dataset\n",
        "  snd_df.loc[ i, \"SND_OSC\"] = osc_snd\n",
        "  snd_df[\"SND_LDL\"][i] = ldl_snd\n",
        "  snd_df[\"Class\"][i] = Class\n",
        "  #snd_df[\"osc_vs_ldl\"][i] = osc_vs_ldl\n",
        "  snd_df[\"centroid_vs_OSC\"][i] = centroid_vs_osc\n",
        "  snd_df[\"centroid_vs_LDL\"][i] = centroid_vs_ldl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkcflhFCZPwK"
      },
      "source": [
        "snd_df.to_csv(PATH + \"snd_df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv1ejuq7UPfC"
      },
      "source": [
        "## form_based vs context_based, factoring in centroid. CADE aligned slices\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKsThwb4l_bY"
      },
      "source": [
        "\n",
        "\n",
        "# creating new column as object\n",
        "#complete_df.loc[ 0 ,\"CADE_slices_male_female\"] = 0\n",
        "#complete_df[\"CADE_slices_male_female\"] = complete_df[\"CADE_slices_male_female\"].astype(object)\n",
        "#fab.loc[0, \"wordform_vector\"] = 0\n",
        "#fab[\"wordform_vector\"] = fab[\"wordform_vector\"].astype(object)\n",
        "\n",
        "\n",
        "form_context_df = pd.DataFrame(columns=[\"Class\", \"form_vs_context_OSC\", \"form_vs_context_LDL\"], dtype=float)\n",
        "path = PATH + 'CADE/models/model_5_50'\n",
        "cade_models = os.listdir(path)\n",
        "print(sorted(cade_models))\n",
        "print(len(cade_models)) # LENGHT IS ONE TOO MANY COZ THERE IS A LOG.TXT FILE\n",
        "\n",
        "\n",
        "# form vs context\n",
        "for i in range(len(complete_df)):\n",
        "  osc_sim_temp = []\n",
        "  ldl_sim_temp = []\n",
        "  #fab_vectors = []\n",
        "  #name = complete_df.loc[i, \"full_name\"].lower().split()[0]\n",
        "  # vectorize target name\n",
        "  #target_name = name.split()\n",
        "  #TW = FormMatrix(target_name, FM.ngram_size, FM.map_dict)\n",
        "  #fab[\"wordform_vector\"][i] = TW.form_matrix\n",
        "\n",
        "  #ldl_sim_temp = []\n",
        "  #ldl_sim_temp = []\n",
        "  #gender_diff_temp = []\n",
        "\n",
        "  # getting character annotation in corpus\n",
        "  id_name = complete_df.loc[i, \"newID\"].lower()\n",
        "  print(i, id_name)\n",
        "  # retrieving author from the character\n",
        "  author = complete_df.loc[i, \"author\"]\n",
        "  Class = complete_df.loc[i, \"class\"]\n",
        "  # retrieving form based semantic vector\n",
        "  osc_vector = complete_df.loc[i, \"osc_vector\"]\n",
        "  ldl_vector = complete_df.loc[i, \"ldl_vector\"]\n",
        "  form_context_df.loc[ i , \"Class\"] = Class\n",
        "  # loop over CADE slices\n",
        "  for file in sorted(cade_models):\n",
        "    # if the slice has the same author of the character\n",
        "    if author in file:\n",
        "      # load the model\n",
        "      model_cade = Word2Vec.load(path + \"/\" + file)\n",
        "      try:\n",
        "        # try if name in vocab\n",
        "\n",
        "        # get context vector for word in cade slice\n",
        "        context_vector = model_cade.wv[id_name]\n",
        "        #calculate centroid of the semantic space\n",
        "        centroid_cade = np.mean(model_cade.wv.vectors, axis = 0)\n",
        "        # calculate similarity between centroid and context, as a baseline\n",
        "        centroid_context = 1 - spatial.distance.cosine(centroid_cade, context_vector)\n",
        "\n",
        "\n",
        "        # calculate similarity between form based and context based ORTHOGRAPHIC SEMANTIC CONSINSTENCY\n",
        "        osc_context = 1 - spatial.distance.cosine(osc_vector, context_vector)\n",
        "\n",
        "        # positive difference signify that osc_vector does better than centroid in resembling the context based\n",
        "        osc_centroid_diff = osc_context - centroid_context\n",
        "        # appending similarity to temp list: OSC\n",
        "        osc_sim_temp.append(osc_centroid_diff)\n",
        "\n",
        "        # calculate similarity between form based and context based LINEAR DISCRIMINANT LEARNING\n",
        "        ldl_context = 1 - spatial.distance.cosine(ldl_vector, context_vector)\n",
        "\n",
        "        # positive difference signify that osc_vector does better than centroid in resembling the context based\n",
        "        ldl_centroid_diff = ldl_context - centroid_context\n",
        "        # appending similarity to temp list: LDL\n",
        "        ldl_sim_temp.append(ldl_centroid_diff)\n",
        "\n",
        "\n",
        "        # most similar neighbors to form based semantic vector in CADE slice ORTHOGRAPHIC SEMANTIC CONSINSTENCY\n",
        "        #osc_m_similars = model_cade.wv.similar_by_vector(osc_vector, topn = 10)\n",
        "        # appeding neighbors to temp list OSC\n",
        "        #osc_most_sim_temp.append(osc_m_similars)\n",
        "\n",
        "        # most similar neighbors to form based semantic vector in CADE slice LINEAR DISCRIMINANT LEARNING\n",
        "        #ldl_m_similars = model_cade.wv.similar_by_vector(ldl_vector, topn = 10)\n",
        "        # appeding neighbors to temp list LDL\n",
        "        #ldl_most_sim_temp.append(ldl_m_similars)\n",
        "        print(\"done\")\n",
        "\n",
        "        #try:\n",
        "\n",
        "          # calculate distance from female and male terms for context vector in cade slice\n",
        "          #gender_diff_cade = diff_sim_wordlist(male_terms, female_terms, context_vector, model_cade)\n",
        "          #gender_diff_temp.append(gender_diff_cade)\n",
        "        #except Exception as e:\n",
        "          #print(e)\n",
        "          #print(\"goin wrong\")\n",
        "\n",
        "      except KeyError:\n",
        "        pass\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "  #adding temp list to dataframe\n",
        "  form_context_df.loc[ i, \"form_vs_context_OSC\"] = np.mean(osc_sim_temp)\n",
        "  form_context_df[\"form_vs_context_LDL\"][i] = np.mean(ldl_sim_temp)\n",
        "  #fab.loc[i , \"cade_vector\"] = np.mean(fab_vectors)\n",
        "  #complete_df[\"most_similar_to_OSC\"][i] = osc_most_sim_temp\n",
        "  #complete_df[\"most_similar_to_LDL\"][i] = ldl_most_sim_temp\n",
        "  #complete_df[\"CADE_slices_male_female\"][i] = gender_diff_temp\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcG6VriXkupD"
      },
      "source": [
        "form_context_df.to_csv(PATH + \"form_context_df.csv\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh9aR-B2UZo7"
      },
      "source": [
        "## Cosine between target and theme words for gender in:\n",
        "- FORMSPACE\n",
        "- SEMANTIC COMPASS for context based\n",
        "\n",
        "- SEMANTIC COMPASS for form based (OSC & LDL)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw5ShsAHrejv"
      },
      "source": [
        "female_terms = [\"she\", \"daughter\", \"hers\", \"her\", \"mother\",\n",
        "\"woman\",\n",
        "\"girl\",\n",
        "\"female\",\n",
        "\"sister\",\n",
        "\"aunt\",\n",
        "\"niece\",]\n",
        "male_terms = [\"he\",\n",
        "\"son\",\n",
        "\"his\",\n",
        "\"him\",\n",
        "\"father\",\n",
        "\"man\",\n",
        "\"boy\",\n",
        "\"male\",\n",
        "\"brother\",\n",
        "\"uncle\",\n",
        "\"nephew\"]\n",
        "\n",
        "centroid = np.mean(compass_model.wv.vectors, axis=0)\n",
        "gender_df = pd.DataFrame(columns=[\"Class\", \"gender\", \"OSC_male_female\" , \"LDL_male_female\", \"context_male_female\", \"WordForm_male_female\"], dtype=float)\n",
        "\n",
        "\n",
        "for i in range(len(complete_df)):\n",
        "  # IN SEMANTIC SPACE COMPASS\n",
        "\n",
        "  #filling up evaluation dataframe\n",
        "  Class = complete_df.loc[i, \"class\"]\n",
        "  gender_df.loc[ i, \"Class\"] = Class\n",
        "  gender = complete_df.loc[i, \"gender\"]\n",
        "  gender_df.loc[ i, \"gender\"] = gender\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "  # getting id of character\n",
        "  id_name = complete_df.loc[i, \"newID\"].lower()\n",
        "  # get context vector based on compass\n",
        "  context_compass_vector = compass_model.wv[id_name]\n",
        "  # get form based vectors\n",
        "  osc_vector = complete_df.loc[i, \"osc_vector\"]\n",
        "\n",
        "  ldl_vector = complete_df.loc[i, \"ldl_vector\"]\n",
        "\n",
        "  # calculating difference in similarity between osc_vector and male & female terms\n",
        "  gender_diff_osc = diff_sim_wordlist(male_terms, female_terms, a_vector = osc_vector, centroid_v=centroid ,a_model = compass_model)\n",
        "\n",
        "  # calculating difference in similarity between ldl_vector and male & female terms\n",
        "  gender_diff_ldl = diff_sim_wordlist(male_terms, female_terms, ldl_vector, centroid, compass_model)\n",
        "\n",
        "  # calculating difference in similarity between context_compass_vector and male & female terms\n",
        "  gender_diff_context = diff_sim_wordlist(male_terms, female_terms, context_compass_vector, centroid, compass_model)\n",
        "\n",
        "\n",
        "\n",
        "  # appending to dataframe\n",
        "  # FACTORING IN THE SIMILARITY TO CENTROID\n",
        "  # IF THE VALUE IS POSITIVE IT MEANS THAT THE SEMANTIC VECTOR DOES BETTER THAN CENTROID\n",
        "  gender_df[\"OSC_male_female\"][i] = gender_diff_osc\n",
        "  gender_df[\"LDL_male_female\"][i] = gender_diff_ldl\n",
        "\n",
        "  gender_df[\"context_male_female\"][i] = gender_diff_context\n",
        "\n",
        "\n",
        "  # IN FORM SPACE\n",
        "  # getting name of character\n",
        "  name = complete_df.loc[i, \"full_name\"].lower().split()[0]\n",
        "  # vectorize target name\n",
        "  target_name = name.split()\n",
        "  TW = FormMatrix(target_name, FM.ngram_size, FM.map_dict)\n",
        "\n",
        "  # computes similarity in form space\n",
        "  form_male_sim = 0\n",
        "  form_female_sim = 0\n",
        "  for m_t in male_terms:\n",
        "    male_sim = 1 - spatial.distance.cosine(TW.form_matrix[0],  FM.form_matrix[FM.word2idx[m_t]])\n",
        "    form_male_sim += male_sim\n",
        "\n",
        "  for f_t in female_terms:\n",
        "    female_sim = 1 - spatial.distance.cosine(TW.form_matrix[0],  FM.form_matrix[FM.word2idx[f_t]])\n",
        "    form_female_sim += female_sim\n",
        "\n",
        "  # positive values indicates that the form vector is closer to male terms\n",
        "  gender_df[\"WordForm_male_female\"][i] = form_male_sim - form_female_sim\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O2y5Tw3UcxX"
      },
      "source": [
        "gender_df.to_csv(PATH + \"gender_df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jomteQt6hduN"
      },
      "source": [
        "## Cosine between target and theme words for age in:\n",
        "- FORMSPACE\n",
        "- SEMANTIC COMPASS for context based\n",
        "\n",
        "- SEMANTIC COMPASS for form based (OSC & LDL)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdHd2h3WhexZ"
      },
      "source": [
        "young_terms = [\"kid\", \"youth\", \"young\", \"youngster\", \"infant\", \"junior\", \"child\", \"adolescent\", \"teenager\"]\n",
        "old_terms = [\"grandfather\", \"grandmother\", \"old\", \"senior\", \"elderly\", \"elder\"]\n",
        "\n",
        "centroid = np.mean(compass_model.wv.vectors, axis=0)\n",
        "age_df = pd.DataFrame(columns=[\"Class\", \"age\", \"OSC_young_old\" , \"LDL_young_old\", \"context_young_old\", \"WordForm_young_old\"], dtype=float)\n",
        "\n",
        "\n",
        "for i in range(len(complete_df)):\n",
        "  # IN SEMANTIC SPACE COMPASS\n",
        "\n",
        "  #filling up evaluation dataframe\n",
        "  Class = complete_df.loc[i, \"class\"]\n",
        "  age_df.loc[ i, \"Class\"] = Class\n",
        "  age = complete_df.loc[i, \"age_recoded\"]\n",
        "  age_df.loc[ i, \"age\"] = age\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "  # getting id of character\n",
        "  id_name = complete_df.loc[i, \"newID\"].lower()\n",
        "  # get context vector based on compass\n",
        "  context_compass_vector = compass_model.wv[id_name]\n",
        "  # get form based vectors\n",
        "  osc_vector = complete_df.loc[i, \"osc_vector\"]\n",
        "\n",
        "  ldl_vector = complete_df.loc[i, \"ldl_vector\"]\n",
        "  \n",
        "  \n",
        "\n",
        "  # calculating difference in similarity between osc_vector and male & female terms\n",
        "  age_diff_osc = diff_sim_wordlist(young_terms, old_terms, a_vector = osc_vector, centroid_v=centroid, a_model = compass_model)\n",
        "\n",
        "  # calculating difference in similarity between ldl_vector and male & female terms\n",
        "  age_diff_ldl = diff_sim_wordlist(young_terms, old_terms, ldl_vector, centroid ,compass_model)\n",
        "\n",
        "  # calculating difference in similarity between context_compass_vector and male & female terms\n",
        "  age_diff_context = diff_sim_wordlist(young_terms, old_terms, context_compass_vector, centroid, compass_model)\n",
        "\n",
        "\n",
        "\n",
        "  # appending to dataframe\n",
        "  # FACTORING IN THE SIMILARITY TO CENTROID\n",
        "  # IF THE VALUE IS POSITIVE IT MEANS THAT THE SEMANTIC VECTOR DOES BETTER THAN CENTROID\n",
        "  age_df[\"OSC_young_old\"][i] = age_diff_osc\n",
        "  age_df[\"LDL_young_old\"][i] = age_diff_ldl\n",
        "  age_df[\"context_young_old\"][i] = age_diff_context\n",
        "\n",
        "  # IN FORM SPACE\n",
        "  # getting name of character\n",
        "  name = complete_df.loc[i, \"full_name\"].lower().split()[0]\n",
        "  # vectorize target name\n",
        "  target_name = name.split()\n",
        "  TW = FormMatrix(target_name, FM.ngram_size, FM.map_dict)\n",
        "\n",
        "  # computes similarity in form space\n",
        "  form_young_sim = 0\n",
        "  form_old_sim = 0\n",
        "  for y_t in young_terms:\n",
        "    young_sim = 1 - spatial.distance.cosine(TW.form_matrix[0],  FM.form_matrix[FM.word2idx[y_t]])\n",
        "    form_young_sim += young_sim\n",
        "\n",
        "  for o_t in old_terms:\n",
        "    old_sim = 1 - spatial.distance.cosine(TW.form_matrix[0],  FM.form_matrix[FM.word2idx[o_t]])\n",
        "    form_old_sim += old_sim\n",
        "\n",
        "  # positive values indicates that the form vector is closer to male terms\n",
        "  age_df[\"WordForm_young_old\"][i] = form_young_sim - form_old_sim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEvSAInYVIBG"
      },
      "source": [
        "age_df.to_csv(PATH + \"age_df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOLK9qcJezkx"
      },
      "source": [
        "# Descriptive Stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLJVFdQIA-Fk"
      },
      "source": [
        "snd_df = pd.read_csv(PATH + \"snd_df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUx6ns_TBITZ"
      },
      "source": [
        "form_context_df = pd.read_csv(PATH + \"form_context_df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sHfEtxxBTnp"
      },
      "source": [
        "age_df = pd.read_csv(PATH + \"age_df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8zGv-krBTup"
      },
      "source": [
        "gender_df = pd.read_csv(PATH + \"gender_df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp1N4FQmoNko"
      },
      "source": [
        "# AVERAGE OF SND AND CONTEXT VS FORM FOR EACH CLASS AND ATTRIBUTES\n",
        "snd_df.groupby(by = [\"Class\"]).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCkvM8rGWI4d"
      },
      "source": [
        "form_context_df.groupby(by = [\"Class\"]).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBuy1x4SLyzB"
      },
      "source": [
        "gender_df.groupby(by = [\"Class\", \"gender\"]).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Kv9mPwnlkVs"
      },
      "source": [
        "age_df.groupby(by = [\"Class\", \"age\"]).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLsdgEMvsnZf"
      },
      "source": [
        "age_df.to_csv(PATH + \"age_df.csv\")\n",
        "gender_df.to_csv(PATH + \"gendef_df.csv\")\n",
        "snd_df.to_csv(PATH + \"snd_df.csv\")\n",
        "form_context_df.to_csv(PATH + \"form_context_df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}